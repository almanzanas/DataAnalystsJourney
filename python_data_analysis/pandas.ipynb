{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with pandas\n",
    "\n",
    "Pandas will make data cleaning and analysis fast in python. It's designed for working with tabular or heterogeneous data. \n",
    "\n",
    "Conventions:\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "## Index\n",
    "\n",
    "* [Introductino to Pandas Data Structures](#introduction-to-pandas-data-structures)\n",
    "    * [Series](#series)\n",
    "    * [DataFrames](#dataframe)\n",
    "    * [Index Object](#index-object)\n",
    "* [Essential Functionality](#essential-functionality)\n",
    "    * [Reindexing](#reindexing)\n",
    "    * [Dropping entries from an Axis](#dropping-entries-from-an-axis)\n",
    "    * [Indexing, Selection and Filtering](#indexing-selection-and-filtering)\n",
    "        * [Indexing options with DataFrame](#indexing-options-with-dataframe)\n",
    "    * [Arithmetic and Data Alignment](#arithmetic-and-data-alignment)\n",
    "        * [Operations between DataFrame and Series](#operations-between-dataframe-and-series)\n",
    "    * [Function Application and Mapping](#function-aplication-and-mapping)\n",
    "        * [Formating with functions](#formating-with-functions)\n",
    "    * [Sorting and Ranking](#sorting-and-ranking)\n",
    "    * [Axis indexes with duplicate labels](#axis-with-duplicate-labels)\n",
    "* [Summarizing and Computing Descriptive Statistics](#summarizing-and-computing-descriptive-statistics)\n",
    "    * [Correlation and Covariance](#correlation-and-covariance)\n",
    "    * [Unique Values, Value counts, and Membership](#unique-values-value-counts-and-membership)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to pandas Data Structures\n",
    "\n",
    "### Series\n",
    "\n",
    "Series is a one-dimensional array-like object containing a sequence of values asociated to a data labels (index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    2\n",
      "2   -3\n",
      "3    9\n",
      "dtype: int64\n",
      "\n",
      "0    6\n",
      "1    2\n",
      "2   -3\n",
      "3    9\n",
      "dtype: int64\n",
      "RangeIndex(start=10, stop=50, step=10)\n",
      "Object n30: -6\n",
      "Greater than 0: \n",
      "10     True\n",
      "20     True\n",
      "30    False\n",
      "40     True\n",
      "dtype: bool\n",
      "And filtering rows: \n",
      "10    5\n",
      "20    3\n",
      "40    8\n",
      "dtype: int64\n",
      "\n",
      "Is index 55 in obj2? \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj = pd.Series([6, 2, -3, 9])\n",
    "print(obj)\n",
    "\n",
    "obj2 = pd.Series([5, 3, -6, 8], index=range(10, 50, 10))\n",
    "print(f\"\\n{obj}\")\n",
    "print(f\"{obj2.index}\")\n",
    "print(f\"Object n30: {obj2[30]}\")\n",
    "print(f\"Greater than 0: \\n{obj2 > 0}\"\n",
    "      # Aplying a filter\n",
    "      f\"\\nAnd filtering rows: \\n{obj2[obj2 > 0]}\")\n",
    "# Operations like NumPy\n",
    "print(f\"\\nIs index 55 in obj2? \\n{55 in obj2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio      35000\n",
      "Texas     71000\n",
      "Oregon    16000\n",
      "Utah       5000\n",
      "dtype: int64\n",
      "\n",
      "{'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
      "\n",
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "dtype: float64\n",
      "\n",
      "Looking for missing data: \n",
      "California     True\n",
      "Ohio          False\n",
      "Oregon        False\n",
      "Texas         False\n",
      "dtype: bool\n",
      "\n",
      "Looking for NOT missing data: \n",
      "California    False\n",
      "Ohio           True\n",
      "Oregon         True\n",
      "Texas          True\n",
      "dtype: bool\n",
      "\n",
      "Filtering missing data: \n",
      "California   NaN\n",
      "dtype: float64\n",
      "Obj3 + Obj4: \n",
      "California         NaN\n",
      "Ohio           70000.0\n",
      "Oregon         32000.0\n",
      "Texas         142000.0\n",
      "Utah               NaN\n",
      "dtype: float64\n",
      "Obj4 with name attribute: \n",
      "state\n",
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "Name: population, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "# Dictionary to pandas Series\n",
    "obj3 = pd.Series(dict)\n",
    "\n",
    "print(f\"{obj3}\")\n",
    "# pandas Series to dictionary\n",
    "print(f\"\\n{obj3.to_dict()}\")\n",
    "\n",
    "# Specifying the index (with miss data)\n",
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(dict, index=states)\n",
    "print(f\"\\n{obj4}\") \n",
    "# Missing data as NaN (Not a Number)\n",
    "# Utah has data but is excluded from 'obj4' because the index\n",
    "\n",
    "print(f\"\\nLooking for missing data: \\n{pd.isna(obj4)}\")\n",
    "print(f\"\\nLooking for NOT missing data: \\n{pd.notna(obj4)}\")\n",
    "# Getting rows with missing data\n",
    "print(f\"\\nFiltering missing data: \\n{obj4[obj4.isna()]}\")\n",
    "\n",
    "# We can do arithmetic operations with two Series, \n",
    "# and automaticaly it aligns the index\n",
    "print(f\"Obj3 + Obj4: \\n{obj3 + obj4}\")\n",
    "\n",
    "# atribute naming for Series\n",
    "obj4.name = \"population\"\n",
    "obj4.index.name = \"state\"\n",
    "print(f\"Obj4 with name attribute: \\n{obj4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "A DataFrame is a table of data wutg irdered and named collection of collumns that can be different value type and it has both a row and column index. You can create a DataFrame with a dictionary of equal length lists or NumPy arrays.\n",
    "\n",
    "Asigning new values to a column in the DataFrame, the new data in the Series or Array must match the length of the dataframe. If we assign a Series, it's labels will be realigned to the DataFrame's index, inserting missing values in any index values not present.\n",
    "\n",
    "*Possible data inputs to the DataFrame constructos*\n",
    "|Type|Notes|\n",
    "|---|---|\n",
    "|2D ndarray| A matrix of data, passing optional row and column labels|\n",
    "|Dictionary of arrays, lists, or tuples |Each sequence becomes a column in the DataFrame; all sequences must be the same length|\n",
    "|NumPy structured/record array| Treated as the “dictionary of arrays” case|\n",
    "|Dictionary of Series| Each value becomes a column; indexes from each Series are unioned together to form the result’s row index if no explicit index is passed|\n",
    "|Dictionary of dictionaries| Each inner dictionary becomes a column; keys are unioned to form the row index as in the “dictionary of Series” case|\n",
    "|List of dictionaries or Series |Each item becomes a row in the DataFrame; unions of dictionary keys or Series indexes become the DataFrame’s column labels|\n",
    "|List of lists or tuples| Treated as the “2D ndarray” case|\n",
    "|Another DataFrame| The DataFrame’s indexes are used unless different ones are passed|\n",
    "|NumPy MaskedArray| Like the “2D ndarray” case except masked values are missing in the DataFrame result|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year   state  pop\n",
      "0  2000    Ohio  1.5\n",
      "1  2001    Ohio  1.7\n",
      "2  2002    Ohio  3.6\n",
      "3  2001  Nevada  2.4\n",
      "4  2002  Nevada  2.9\n",
      "5  2003  Nevada  3.2\n",
      "6  2002  Oregon  2.4\n",
      "7  2003  Oregon  3.1\n",
      "8  2004   Texas  3.3\n",
      "9  2005   Texas  2.9\n",
      "\n",
      "   year   state  pop\n",
      "0  2000    Ohio  1.5\n",
      "1  2001    Ohio  1.7\n",
      "2  2002    Ohio  3.6\n",
      "3  2001  Nevada  2.4\n",
      "4  2002  Nevada  2.9\n",
      "\n",
      "   year   state  pop\n",
      "5  2003  Nevada  3.2\n",
      "6  2002  Oregon  2.4\n",
      "7  2003  Oregon  3.1\n",
      "8  2004   Texas  3.3\n",
      "9  2005   Texas  2.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "data = {\n",
    "    \"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\", \"Oregon\",\n",
    "              \"Oregon\", \"Texas\", \"Texas\",],\n",
    "    \"year\": [2000, 2001, 2002, 2001, 2002, 2003, 2002, 2003, 2004, 2005],\n",
    "    \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2, 2.4, 3.1, 3.3, 2.9]\n",
    "    }\n",
    "\n",
    "# We can define columns order making the DataFrame\n",
    "df = DataFrame(data, columns=[\"year\", \"state\", \"pop\"])\n",
    "print(f\"{df}\")\n",
    "\n",
    "# For large DataFrame, we can see the first 5 rows with 'head()'\n",
    "print(f\"\\n{df.head()}\")\n",
    "# And we can see the las 5 rows with 'tail()'\n",
    "print(f\"\\n{df.tail()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns df2: Index(['year', 'state', 'pop', 'debt'], dtype='object')\n",
      "States: \n",
      "0      Ohio\n",
      "1      Ohio\n",
      "2      Ohio\n",
      "3    Nevada\n",
      "4    Nevada\n",
      "5    Nevada\n",
      "6    Oregon\n",
      "7    Oregon\n",
      "8     Texas\n",
      "9     Texas\n",
      "Name: state, dtype: object\n",
      "Printing years: \n",
      "0    2000\n",
      "1    2001\n",
      "2    2002\n",
      "3    2001\n",
      "4    2002\n",
      "5    2003\n",
      "6    2002\n",
      "7    2003\n",
      "8    2004\n",
      "9    2005\n",
      "Name: year, dtype: int64\n",
      "\n",
      "Retrieving by position: \n",
      "year     2002\n",
      "state    Ohio\n",
      "pop       3.6\n",
      "debt      NaN\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\", \"Oregon\",\n",
    "              \"Oregon\", \"Texas\", \"Texas\",],\n",
    "    \"year\": [2000, 2001, 2002, 2001, 2002, 2003, 2002, 2003, 2004, 2005],\n",
    "    \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2, 2.4, 3.1, 3.3, 2.9]\n",
    "    }\n",
    "\n",
    "# Adding an extra column for missing data\n",
    "df2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])\n",
    "print(f\"Columns df2: {df2.columns}\")\n",
    "print(f\"States: \\n{df2['state']}\"\n",
    "      f\"\\nPrinting years: \\n{df2.year}\")\n",
    "print(f\"\\nRetrieving by position: \\n{df2.iloc[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year   state  pop  debt  eastern\n",
      "0  2000    Ohio  1.5   1.0     True\n",
      "1  2001    Ohio  1.7   2.0     True\n",
      "2  2002    Ohio  3.6   3.0     True\n",
      "3  2001  Nevada  2.4   4.0    False\n",
      "4  2002  Nevada  2.9   5.0    False\n",
      "5  2003  Nevada  3.2   6.0    False\n",
      "6  2002  Oregon  2.4   7.0    False\n",
      "7  2003  Oregon  3.1   8.0    False\n",
      "8  2004   Texas  3.3   9.0    False\n",
      "9  2005   Texas  2.9  10.0    False\n",
      "\n",
      "Deleting 'eastern' column: Index(['year', 'state', 'pop', 'debt'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\", \"Oregon\",\n",
    "              \"Oregon\", \"Texas\", \"Texas\",],\n",
    "    \"year\": [2000, 2001, 2002, 2001, 2002, 2003, 2002, 2003, 2004, 2005],\n",
    "    \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2, 2.4, 3.1, 3.3, 2.9]\n",
    "    }\n",
    "df2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])\n",
    "\n",
    "# Modifying 'debt' column with array \n",
    "df2[\"debt\"] = np.arange(1.,11.0)\n",
    "\n",
    "# Creating a 'eastern' column for 'Ohio', as boolean\n",
    "df2[\"eastern\"] = df2[\"state\"] == \"Ohio\"\n",
    "print(f\"{df2}\")\n",
    "\n",
    "# Removing \"eastern\" column\n",
    "del df2[\"eastern\"]\n",
    "print(f\"\\nDeleting 'eastern' column: {df2.columns}\")\n",
    "\n",
    "\"\"\"\n",
    "    The column returned from indexing a DataFrame is a 'view', not a copy, \n",
    "    thus in-place modifications to Series will be reflected in the DataFrame.\n",
    "    The column can be copied with 'copy' method from Series.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        2000  2001  2002\n",
      "Ohio     1.5   1.7   3.6\n",
      "Nevada   NaN   2.4   2.9\n",
      "\n",
      "      Ohio  Nevada\n",
      "2001   1.7     2.4\n",
      "2002   3.6     2.9\n",
      "2003   NaN     NaN\n",
      "\n",
      "      Ohio  Nevada\n",
      "2000   1.5     NaN\n",
      "2001   1.7     2.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "populations = {\n",
    "    \"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n",
    "    \"Nevada\": {2001: 2.4, 2002: 2.9}\n",
    "}\n",
    "# In a DataFrame, the outer dictionary keys will be the columns\n",
    "frame3 = pd.DataFrame(populations)\n",
    "\n",
    "print(f\"{frame3.T}\")\n",
    "# Trasposing discards the column data types if the columns don't have\n",
    "# all the same data type. Transposing back it becomes pure python objects\n",
    "\n",
    "# Specifying the index\n",
    "f3ind = pd.DataFrame(populations, index=[2001, 2002, 2003])\n",
    "print(f\"\\n{f3ind}\")\n",
    "\n",
    "serie_data = {\"Ohio\": frame3[\"Ohio\"][:-1],\n",
    "              \"Nevada\": frame3[\"Nevada\"][:2],\n",
    "              }\n",
    "sdata = pd.DataFrame(serie_data)\n",
    "print(f\"\\n{sdata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state  Ohio  Nevada\n",
      "year               \n",
      "2000    1.5     NaN\n",
      "2001    1.7     2.4\n",
      "2002    3.6     2.9\n",
      "To numpy: \n",
      "[[1.5 nan]\n",
      " [1.7 2.4]\n",
      " [3.6 2.9]]\n",
      "\n",
      "{'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada', 'Oregon', 'Oregon', 'Texas', 'Texas'], 'year': [2000, 2001, 2002, 2001, 2002, 2003, 2002, 2003, 2004, 2005], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2, 2.4, 3.1, 3.3, 2.9]}\n",
      "to numpy: \n",
      "[['Ohio' 2000 1.5]\n",
      " ['Ohio' 2001 1.7]\n",
      " ['Ohio' 2002 3.6]\n",
      " ['Nevada' 2001 2.4]\n",
      " ['Nevada' 2002 2.9]\n",
      " ['Nevada' 2003 3.2]\n",
      " ['Oregon' 2002 2.4]\n",
      " ['Oregon' 2003 3.1]\n",
      " ['Texas' 2004 3.3]\n",
      " ['Texas' 2005 2.9]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "populations = {\n",
    "    \"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n",
    "    \"Nevada\": {2001: 2.4, 2002: 2.9}\n",
    "}\n",
    "\n",
    "frame3 = pd.DataFrame(populations)\n",
    "\n",
    "frame3.index.name = \"year\"\n",
    "frame3.columns.name = \"state\"\n",
    "print(f\"{frame3}\")\n",
    "\n",
    "# DataFrame doesn't have a name attribute. 'to_numpy()' returns the data\n",
    "print(f\"To numpy: \\n{frame3.to_numpy()}\")\n",
    "\n",
    "data = {\n",
    "    \"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\", \"Oregon\",\n",
    "              \"Oregon\", \"Texas\", \"Texas\",],\n",
    "    \"year\": [2000, 2001, 2002, 2001, 2002, 2003, 2002, 2003, 2004, 2005],\n",
    "    \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2, 2.4, 3.1, 3.3, 2.9]\n",
    "    }\n",
    "\n",
    "frame2 = pd.DataFrame(data)\n",
    "# Data type will be acomodated to all of the columns if there are different dtp\n",
    "print(f\"\\n{data}\")\n",
    "print(f\"to numpy: \\n{frame2.to_numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Object\n",
    "\n",
    "Index objects are responsible for holding the axis labels, including DataFrame's column names. Any sequence of labels used constructing a Series or DF is internally converted to an Index.\n",
    "\n",
    "A pandas Index can contain duplicate labels, but a Python sets cannot.\n",
    "\n",
    "*Some Index methods and properties*\n",
    "|Method/Property| Description|\n",
    "|---|---|\n",
    "|append() |Concatenate with additional Index objects, producing a new Index|\n",
    "|difference() |Compute set difference as an Index|\n",
    "|intersection() |Compute set intersection|\n",
    "|union() |Compute set union|\n",
    "|isin() |Compute Boolean array indicating whether each value is contained in the passed collection|\n",
    "|delete() |Compute new Index with element at Index i deleted|\n",
    "|drop() |Compute new Index by deleting passed values|\n",
    "|insert() |Compute new Index by inserting element at Index i|\n",
    "|is_monotonic |Returns True if each element is greater than or equal to the previous element|\n",
    "|is_unique |Returns True if the Index has no duplicate values|\n",
    "|unique() |Compute the array of unique values in the Index|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'b', 'c'], dtype='object')\n",
      "0    1.5\n",
      "1   -3.4\n",
      "2    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "obj = pd.Series(np.arange(3), index=[\"a\",\"b\",\"c\"])\n",
    "index = obj.index \n",
    "print(f\"{index}\")\n",
    "# Index objects are immutable \n",
    "\n",
    "labels = pd.Index(np.arange(3))\n",
    "\n",
    "obj2 = pd.Series([1.5, -3.4, 0], index=labels)\n",
    "print(f\"{obj2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Functionality\n",
    "\n",
    "### Reindexing \n",
    "\n",
    "`reindex()` create a new object with the values rearranged to align with the new index and itroduces new values if it's necesary.\n",
    "\n",
    "For ordered data, with `method=ffill` we can interpolate or fill the values when reindexing.\n",
    "\n",
    "Working with DataFrames, you can reindex the index (row), columns, or both.\n",
    "\n",
    "*reindex function arguments*\n",
    "|Argument|Description|\n",
    "|---|---|\n",
    "|labels| New sequence to use as an index. Can be Index instance or any other sequence-like Python data structure. An Index will be used exactly as is without any copying.|\n",
    "|index |Use the passed sequence as the new index labels.|\n",
    "|columns |Use the passed sequence as the new column labels.|\n",
    "|axis |The axis to reindex, whether \"index\" (rows) or \"columns\". The default is \"index\". You can alternately do reindex(index=new_labels) or reindex(columns=new_labels).|\n",
    "|method |Interpolation (fill) method; \"ffill\" fills forward, while \"bfill\" fills backward.|\n",
    "|fill_value| Substitute value to use when introducing missing data by reindexing. Use fill_value=\"missing\" (the default behavior) when you want absent labels to have null values in the result.|\n",
    "|limit |When forward filling or backfilling, the maximum size gap (in number of elements) to fill.|\n",
    "|tolerance| When forward filling or backfilling, the maximum size gap (in absolute numeric distance) to fill for inexact matches.|\n",
    "|level |Match simple Index on level of MultiIndex; otherwise select subset of.|\n",
    "|copy |If True, always copy underlying data even if the new index is equivalent to the old index; if False, do not copy the data when the indexes are equivalent.|\n",
    "\n",
    "Reindex with `loc` operator only works if all of the new index labels already exist in the DataFrame (whereas `reindex` will insert missing data for new labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4.5\n",
      "1    7.2\n",
      "2   -5.2\n",
      "3    3.7\n",
      "dtype: float64\n",
      "\n",
      " Reindex new object to: \n",
      "a   NaN\n",
      "b   NaN\n",
      "c   NaN\n",
      "d   NaN\n",
      "e   NaN\n",
      "dtype: float64\n",
      "\n",
      "0      blue\n",
      "3    purple\n",
      "6    yellow\n",
      "dtype: object\n",
      "And reindex with method=ffill\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      blue\n",
       "1      blue\n",
       "2      blue\n",
       "3    purple\n",
       "4    purple\n",
       "5    purple\n",
       "6    yellow\n",
       "7    yellow\n",
       "8    yellow\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.Series([4.5, 7.2, -5.2, 3.7])\n",
    "print(f\"{obj}\")\n",
    "\n",
    "obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "print(f\"\\n Reindex new object to: \\n{obj2}\")\n",
    "\n",
    "# Reindex with ffill\n",
    "obj3= pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0,3,6])\n",
    "print(f\"\\n\\n{obj3}\\nAnd reindex with method=ffill\")\n",
    "obj3.reindex(np.arange(9), method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ohio  Texas  California\n",
      "a     0      1           2\n",
      "d     3      4           5\n",
      "c     6      7           8\n",
      "\n",
      "Reindex in new object:\n",
      "   Ohio  Texas  California\n",
      "a   0.0    1.0         2.0\n",
      "b   NaN    NaN         NaN\n",
      "c   6.0    7.0         8.0\n",
      "d   3.0    4.0         5.0\n",
      "\n",
      "   Texas  Utah  California\n",
      "a      1   NaN           2\n",
      "d      4   NaN           5\n",
      "c      7   NaN           8\n",
      "\n",
      "Reindex with loc:\n",
      "   California  Texas\n",
      "a           2      1\n",
      "d           5      4\n",
      "c           8      7\n"
     ]
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.arange(9).reshape((3,3)),\n",
    "                     index=[\"a\", \"d\", \"c\"],\n",
    "                     columns=[\"Ohio\", \"Texas\", \"California\"])\n",
    "print(f\"{frame}\")\n",
    "\n",
    "frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "print(f\"\\nReindex in new object:\\n{frame2}\")\n",
    "\n",
    "# Reindexing columns\n",
    "states = [\"Texas\", \"Utah\", \"California\"]\n",
    "print(f\"\\n{frame.reindex(columns=states)}\")\n",
    "#frame.reindex(states, axis=\"columns\")\n",
    "\n",
    "print(f\"\\nReindex with loc:\"\n",
    "      f\"\\n{frame.loc[['a','d','c'], ['California','Texas']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Entries from an Axis\n",
    "\n",
    "`drop()` method will retirn a new object with the indicated values deleted from an axis.\n",
    "\n",
    "In a DataFrame you can drop using the axis name or index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original object: \n",
      "a    0.0\n",
      "b    1.0\n",
      "c    2.0\n",
      "d    3.0\n",
      "e    4.0\n",
      "dtype: float64\n",
      "new object with drop: \n",
      "a    0.0\n",
      "b    1.0\n",
      "e    4.0\n",
      "dtype: float64\n",
      "\n",
      "Original DataFrame: \n",
      "   Ohio  Texas  California  Utah\n",
      "a     0      1           2     3\n",
      "b     4      5           6     7\n",
      "c     8      9          10    11\n",
      "d    12     13          14    15\n",
      "\n",
      "DataFrame dropping two index: \n",
      "   Ohio  Texas  California  Utah\n",
      "a     0      1           2     3\n",
      "c     8      9          10    11\n",
      "\n",
      "DataFrame dropping 'California' column:\n",
      "   Ohio  Texas  Utah\n",
      "a     0      1     3\n",
      "b     4      5     7\n",
      "c     8      9    11\n",
      "d    12     13    15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "print(f\"Original object: \\n{obj}\")\n",
    "\n",
    "dp_obj = obj.drop ([\"d\", \"c\"])\n",
    "print(f\"new object with drop: \\n{dp_obj}\")\n",
    "\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "                     columns=[\"Ohio\", \"Texas\", \"California\", \"Utah\"])\n",
    "\n",
    "print(f\"\\nOriginal DataFrame: \\n{frame}\")\n",
    "\n",
    "print(f\"\\nDataFrame dropping two index: \\n{frame.drop(index=['b', 'd'])}\")\n",
    "\n",
    "# drop column with 'axis=1' or 'axis=\"columns\"' \n",
    "print(f\"\\nDataFrame dropping 'California' column:\"\n",
    "      f\"\\n{frame.drop(columns=['California'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Indexing, Selection, and Filtering\n",
    "\n",
    "The preferred way to select index values is with the special `loc` operator; `loc` works with labels and `iloc` works with integers. That's because indexing with '[ ]' will treat integers as labels if the index conains integers, so de behaviour differs depending on the data type of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object1 loc[b:d]: \n",
      "b    1.0\n",
      "c    2.0\n",
      "d    3.0\n",
      "dtype: float64\n",
      "\n",
      "Object2 iloc[[0,1,3]]: \n",
      "10    0.0\n",
      "20    1.0\n",
      "40    3.0\n",
      "dtype: float64\n",
      "\n",
      "Object1 iloc[[0,1,3]]: \n",
      "a    0.0\n",
      "b    1.0\n",
      "d    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "obj1 = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "obj2 = pd.Series(np.arange(4.), index=[10, 20, 30, 40])\n",
    "\n",
    "print(f\"Object1 loc[b:d]: \\n{obj1.loc['b':'d']}\")\n",
    "print(f\"\\nObject2 iloc[[0,1,3]]: \\n{obj2.iloc[[0, 1, 3]]}\")\n",
    "print(f\"\\nObject1 iloc[[0,1,3]]: \\n{obj1.iloc[[0, 1, 3]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "             a   b   c   d\n",
      "Ohio         0   1   2   3\n",
      "Texas        4   5   6   7\n",
      "California   8   9  10  11\n",
      "Utah        12  13  14  15\n",
      "\n",
      "Column 'b': \n",
      "Ohio           1\n",
      "Texas          5\n",
      "California     9\n",
      "Utah          13\n",
      "Name: b, dtype: int32\n",
      "\n",
      "Columns 'b','d': \n",
      "             b   d\n",
      "Ohio         1   3\n",
      "Texas        5   7\n",
      "California   9  11\n",
      "Utah        13  15\n",
      "\n",
      "Rows with column 'c' > 5: \n",
      "             a   b   c   d\n",
      "Texas        4   5   6   7\n",
      "California   8   9  10  11\n",
      "Utah        12  13  14  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=[\"Ohio\", \"Texas\", \"California\", \"Utah\"],\n",
    "                     columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "print(f\"DataFrame: \\n{frame}\")\n",
    "\n",
    "# indexing into DataFrame\n",
    "print(f\"\\nColumn 'b': \\n{frame['b']}\")\n",
    "print(f\"\\nColumns 'b','d': \\n{frame[['b','d']]}\")\n",
    "print(f\"\\nRows with column 'c' > 5: \\n{frame[frame['c'] > 5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California Data: \n",
      "a     8\n",
      "b     9\n",
      "c    10\n",
      "d    11\n",
      "Name: California, dtype: int32\n",
      "\n",
      "Indexes 0 and 2: \n",
      "            a  b   c   d\n",
      "Ohio        0  1   2   3\n",
      "California  8  9  10  11\n",
      "\n",
      "Texas and c, d columns: \n",
      "c    6\n",
      "d    7\n",
      "Name: Texas, dtype: int32\n",
      "\n",
      "iloc[:,:3][frame.c > 5]: \n",
      "             a   b   c\n",
      "Texas        4   5   6\n",
      "California   8   9  10\n",
      "Utah        12  13  14\n"
     ]
    }
   ],
   "source": [
    "### Selection on DataFrame with 'loc' and 'iloc'\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=[\"Ohio\", \"Texas\", \"California\", \"Utah\"],\n",
    "                     columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "print(f\"California Data: \\n{frame.loc['California']}\")\n",
    "print(f\"\\nIndexes 0 and 2: \\n{frame.iloc[['0','2']]}\")\n",
    "print(f\"\\nTexas and c, d columns: \\n{frame.loc['Texas', ['c','d']]}\")\n",
    "print(f\"\\niloc[:,:3][frame.c > 5]: \\n{frame.iloc[:,:3][frame.c > 5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Indexing options with DataFrame*\n",
    "\n",
    "|Type|Notes|\n",
    "|---|---|\n",
    "|df[column] |Select single column or sequence of columns from the DataFrame; special case conveniences: Boolean array (filter rows), slice (slice rows), or Boolean DataFrame (set values based on some criterion) |\n",
    "|df.loc[rows] |Select single row or subset of rows from the DataFrame by label|\n",
    "|df.loc[:, cols] |Select single column or subset of columns by label|\n",
    "|df.loc[rows, cols] |Select both row(s) and column(s) by label|\n",
    "|df.iloc[rows] |Select single row or subset of rows from the DataFrame by integer position|\n",
    "|df.iloc[:, cols] |Select single column or subset of columns by integer position|\n",
    "|df.iloc[rows, cols] |Select both row(s) and column(s) by integer position|\n",
    "|df.at[row, col] |Select a single scalar value by row and column label|\n",
    "|df.iat[row, col] |Select a single scalar value by row and column position (integers)|\n",
    "|reindex method |Select either rows or columns by labels|\n",
    "\n",
    "Working with integers in pandas work differently from built-in Python data structures. With a Series `pd.Series(np.arange(3.))` you can't use `ser[-1]` but `ser.iloc[-1]` will work. But if the index is noninteger such as 'a, b, c', `ser[-2]` will work too.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: \n",
      "             a   b   c   d\n",
      "Ohio         0   1   2   3\n",
      "Texas        4   5   6   7\n",
      "California   8   9  10  11\n",
      "Utah        12  13  14  15\n",
      "\n",
      "Column 'a' = 1: \n",
      "            a   b   c   d\n",
      "Ohio        1   1   2   3\n",
      "Texas       1   5   6   7\n",
      "California  1   9  10  11\n",
      "Utah        1  13  14  15 \n",
      "\n",
      "Row 2 = 5: \n",
      "            a   b   c   d\n",
      "Ohio        1   1   2   3\n",
      "Texas       1   5   6   7\n",
      "California  5   5   5   5\n",
      "Utah        1  13  14  15 \n"
     ]
    }
   ],
   "source": [
    "### Modifying data from DataFrame\n",
    "\n",
    "frame = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                     index=[\"Ohio\", \"Texas\", \"California\", \"Utah\"],\n",
    "                     columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "print(f\"Original Data: \\n{frame}\")\n",
    "\n",
    "frame_mod1 = frame.loc[:,\"a\"] = 1\n",
    "print(f\"\\nColumn 'a' = 1: \\n{frame} \")\n",
    "\n",
    "frame_mod2 = frame.iloc[2] = 5\n",
    "print(f\"\\nRow 2 = 5: \\n{frame} \")\n",
    "\n",
    "# watch frame_mod* are not copies, are views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic and Data Alignment\n",
    "\n",
    "When you adds objects summing two series, if any index pairs are not the same, the respective index in the result will be the union of the index pairs, producing missiong values in the label locations that don't overlap. Then, in DataFrames have to match to return the unions of the ones in each DataFrame, the rest data which does not matcc will be NaN.\n",
    "\n",
    "*Flexible arithmetic methods*\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|add, radd |Methods for addition (+)|\n",
    "|sub, rsub |Methods for subtraction (-)|\n",
    "|div, rdiv |Methods for division (/)|\n",
    "|floordiv, rfloordiv |Methods for floor division (//)|\n",
    "|mul, rmul |Methods for multiplication (*)|\n",
    "|pow, rpow |Methods for exponentiation (**)|\n",
    "\n",
    "In that table, each method has a counterpart starting with *r* meaning *reverse*. Then, `1 / df1` are equivalent to `df1.rdv(1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            b   c     d   e\n",
       "Colorado  NaN NaN   NaN NaN\n",
       "Ohio      3.0 NaN   6.0 NaN\n",
       "Oregon    NaN NaN   NaN NaN\n",
       "Texas     9.0 NaN  12.0 NaN\n",
       "Utah      NaN NaN   NaN NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list(\"bcd\"),\n",
    "                   index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list(\"bde\"),\n",
    "                   index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "df1 + df2\n",
    "## Only Texas and Ohio with B 'b' and 'd' columns match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      a     b     c     d   e\n",
      "0   0.0   2.0   4.0   6.0 NaN\n",
      "1   9.0  11.0  13.0  15.0 NaN\n",
      "2  18.0  20.0  22.0  24.0 NaN\n",
      "3   NaN   NaN   NaN   NaN NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a     b     c     d     e\n",
       "0   0.0   2.0   4.0   6.0   4.0\n",
       "1   9.0  11.0  13.0  15.0   9.0\n",
       "2  18.0  20.0  22.0  24.0  14.0\n",
       "3  15.0  16.0  17.0  18.0  19.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),\n",
    "                    columns=list(\"abcd\"))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),\n",
    "                    columns=list(\"abcde\"))\n",
    "print(df1+df2)\n",
    "# Filling df1 + df2 NaN values\n",
    "df1.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations between DataFrame and Series\n",
    "\n",
    "With NumPy arrays, if you have an one dimensional array and a two dimensional array, you want to substract the data of one-dimensional from two-dimensional array. The operation is performed once for each row (this is referred to as broadcasting). Operations between DataFrame and Series are similar, matches the index of the Series on the columns of the DataFrame. Also, you can specified the index to perform the arithmetic method like `sub()`, the axis that you pass is the 'axis to match on'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "          b     d     e\n",
      "Utah    0.0   1.0   2.0\n",
      "Ohio    3.0   4.0   5.0\n",
      "Texas   6.0   7.0   8.0\n",
      "Oregon  9.0  10.0  11.0\n",
      "Series1: \n",
      "b    0.0\n",
      "d    1.0\n",
      "e    2.0\n",
      "Name: Utah, dtype: float64\n",
      "\n",
      "DataFrame - Series1: \n",
      "          b    d    e\n",
      "Utah    0.0  0.0  0.0\n",
      "Ohio    3.0  3.0  3.0\n",
      "Texas   6.0  6.0  6.0\n",
      "Oregon  9.0  9.0  9.0\n",
      "\n",
      "Substracting from axis='index':\n",
      "          b    d    e\n",
      "Utah   -1.0  0.0  1.0\n",
      "Ohio   -1.0  0.0  1.0\n",
      "Texas  -1.0  0.0  1.0\n",
      "Oregon -1.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "frame = pd.DataFrame(np.arange(12.).reshape((4,3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "series1 = frame.iloc[0]\n",
    "series2 = frame[\"d\"]\n",
    "print(f\"DataFrame:\\n{frame}\")\n",
    "print(f\"Series1: \\n{series1}\")\n",
    "print(f\"\\nDataFrame - Series1: \\n{frame-series1}\")\n",
    "\n",
    "print(f\"\\nSubstracting from axis='index':\\n{frame.sub(series2, axis='index')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Aplication and Mapping\n",
    "\n",
    "NumPy ufuncs also work with pandas.\n",
    "\n",
    "You can apply a function on one-dimensional arrays to each column or row using `apply()` method from DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "               b         d         e\n",
      "Utah    0.449770  1.675518 -0.045813\n",
      "Ohio    0.970555  0.446453 -1.597612\n",
      "Texas  -0.338836 -0.164289 -0.338806\n",
      "Oregon -0.165150 -0.674075  1.129830\n",
      "\n",
      "DataFrame with np.abs():\n",
      "               b         d         e\n",
      "Utah    0.449770  1.675518  0.045813\n",
      "Ohio    0.970555  0.446453  1.597612\n",
      "Texas   0.338836  0.164289  0.338806\n",
      "Oregon  0.165150  0.674075  1.129830\n",
      "\n",
      "Applying function (max - min):\n",
      "b    1.309390\n",
      "d    2.349593\n",
      "e    2.727442\n",
      "dtype: float64\n",
      "\n",
      "Applying function (max - min) on columns:\n",
      "Utah      1.721332\n",
      "Ohio      2.568167\n",
      "Texas     0.174546\n",
      "Oregon    1.803905\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "\n",
    "def f1(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "print(f\"DataFrame:\\n{frame}\")\n",
    "print(f\"\\nDataFrame with np.abs():\\n{np.abs(frame)}\")\n",
    "print(f\"\\nApplying function (max - min):\\n{frame.apply(f1)}\")\n",
    "print(f\"\\nApplying function (max - min) on columns:\"\n",
    "      f\"\\n{frame.apply(f1, axis='columns')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formating with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating min and max from DF: \n",
      "            b         d         e\n",
      "min -1.261568 -0.666499 -0.599034\n",
      "max  1.761770  1.475769  0.132470\n",
      "\n",
      "Formating two decimals on DF: \n",
      "            b      d      e\n",
      "Utah    -1.26  -0.67   0.03\n",
      "Ohio    -0.75   0.29   0.02\n",
      "Texas    1.76   0.62   0.13\n",
      "Oregon   0.17   1.48  -0.60\n",
      "\n",
      "Formating column 'e': \n",
      "Utah       0.03\n",
      "Ohio       0.02\n",
      "Texas      0.13\n",
      "Oregon    -0.60\n",
      "Name: e, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "\n",
    "# Extracting min and max values\n",
    "def f2(x):\n",
    "    \"\"\"Return a Series with min value, max value\"\"\"\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "\n",
    "## Formating the DataFrame\n",
    "def format2(x):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "print(f\"Calculating min and max from DF: \\n{frame.apply(f2)}\")\n",
    "print(f\"\\nFormating two decimals on DF: \\n{frame.map(format2)}\")\n",
    "print(f\"\\nFormating column 'e': \\n{frame['e'].map(format2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Ranking\n",
    "\n",
    "Sorting a dataset by labels you can use `sort_index()` method, and sorting by values with `sort_values()` method. Sorting by default is ascending, but with `ascending=\"False\"` argument you can change it. Sorting values provides you the posibility to choose where NaN values goes with `na_position=\"first\"` argument. Working with DataFrames, you can pass column name in `sort_values(\"column\")` argument or you can pass multiple column names with a list.\n",
    "\n",
    "Ranking assing a rank to each value, ascending by default. The `rank()` method print the Series or DataFrame and replace the values with their corresponding ranking. For DataFrames you can choose columns or index.\n",
    "\n",
    "*Tie-breaking methods with rank*\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|\"average\" |Default: assign the average rank to each entry in the equal group|\n",
    "|\"min\" |Use the minimum rank for the whole group|\n",
    "|\"max\" |Use the maximum rank for the whole group|\n",
    "|\"first\" |Assign ranks in the order the values appear in the data|\n",
    "|\"dense\" |Like method=\"min\", but ranks always increase by 1 between groups rather than the number of equal elements in a group|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting obj index:\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    0\n",
      "e    4\n",
      "dtype: int32\n",
      "\n",
      "Sorting frame index: \n",
      "       a  b  c  d\n",
      "three  1  2  3  0\n",
      "one    5  6  7  4\n",
      "\n",
      "Sorting frame values c: \n",
      "       d  a  b  c\n",
      "one    4  5  6  7\n",
      "three  0  1  2  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                     index=[\"three\", \"one\"],\n",
    "                     columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "\n",
    "obj = pd.Series(np.arange(5), index=[\"d\", \"a\", \"b\", \"c\", \"e\"])\n",
    "\n",
    "print(f\"Sorting obj index:\\n{obj.sort_index()}\")\n",
    "print(f\"\\nSorting frame index: \\n{frame.sort_index(axis='columns')}\")\n",
    "print(f\"\\nSorting frame values c: \\n{frame.sort_values('c', ascending=False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between original Object and Ranking:\n",
      "   Original  Ranking\n",
      "0         7      6.5\n",
      "1        -5      1.0\n",
      "2         7      6.5\n",
      "3         4      4.5\n",
      "4         2      3.0\n",
      "5         0      2.0\n",
      "6         4      4.5\n",
      "\n",
      "Original DataFrame: \n",
      "              d         a         b         c\n",
      "three  0.127778  1.205931 -0.148343 -2.544499\n",
      "one    0.207475 -1.224809 -0.987458  2.303895\n",
      "four  -0.156729 -1.092226  0.618376 -0.479203\n",
      "two   -1.468082  0.127942 -1.560428 -0.819110\n",
      "\n",
      "DataFrame Ranking columns: \n",
      "         d    a    b    c\n",
      "three  3.0  4.0  2.0  1.0\n",
      "one    3.0  1.0  2.0  4.0\n",
      "four   3.0  1.0  4.0  2.0\n",
      "two    2.0  4.0  1.0  3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame(np.random.standard_normal((4, 4)),\n",
    "                     index=[\"three\", \"one\", \"four\", \"two\"],\n",
    "                     columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "\n",
    "objr = obj.rank()\n",
    "objframe = pd.DataFrame({\"Original\": obj, \"Ranking\": objr})\n",
    "\n",
    "print(f\"Comparison between original Object and Ranking:\\n{objframe}\")\n",
    "\n",
    "print(f\"\\nOriginal DataFrame: \\n{frame}\")\n",
    "print(f\"\\nDataFrame Ranking columns: \\n{frame.rank(axis='columns')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis with Duplicate Labels\n",
    "\n",
    "Unique labels for pandas functions it's not mandatory. The property `is_unique` of the index tells whether or not its labels are unique. When you select data in a series or dataframe, the output will be diferent whether the indexes are unique or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'obj' unique?: False\n",
      "\n",
      "Obj 'a': \n",
      "a    0\n",
      "a    1\n",
      "dtype: int32\n",
      "\n",
      "Obj 'c': \n",
      "4\n",
      "\n",
      "DF index 'a': \n",
      "          0         1         2\n",
      "a  0.797632 -0.520406 -1.703885\n",
      "a -0.425133 -2.437056 -0.235144\n",
      "\n",
      "DF index 'c': \n",
      "0   -1.701084\n",
      "1    0.742129\n",
      "2    0.437525\n",
      "Name: c, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df = pd.DataFrame(np.random.standard_normal((5, 3)),\n",
    "                  index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "obj = pd.Series(np.arange(5), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "\n",
    "print(f\"Is 'obj' unique?: {obj.index.is_unique}\")\n",
    "print(f\"\\nObj 'a': \\n{obj['a']}\")\n",
    "print(f\"\\nObj 'c': \\n{obj['c']}\")\n",
    "\n",
    "print(f\"\\nDF index 'a': \\n{df.loc['a']}\")\n",
    "print(f\"\\nDF index 'c': \\n{df.loc['c']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing and Computing Descriptive Statistics\n",
    "pandas objects have mathematical and statistical methods, most of them are reductions or summary statistics which returns a single value (sum, mean). The `sum()` method for a DF returns a Series containing column sums; specifying axis=\"columns\" or axis=1 will sum across the columns instead. When a columns or row contains only NA values, the sum is 0 but if any value is not NA, then the result is NA. This can be disabled with `skipna=False` option.\n",
    "\n",
    "*Options for reductions methods*\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|axis |Axis to reduce over; “index” for DataFrame’s rows and “columns” for columns|\n",
    "|skipna |Exclude missing values; True by default|\n",
    "|level |Reduce grouped by level if the axis is hierarchically indexed (MultiIndex)|\n",
    "\n",
    "\n",
    "*Descriptive and summary statistics*\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|count |Number of non-NA values|\n",
    "|describe |Compute set of summary statistics|\n",
    "|min, max |Compute minimum and maximum values|\n",
    "|argmin, argmax |Compute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects|\n",
    "|idxmin, idxmax |Compute index labels at which minimum or maximum value is obtained, respectively|\n",
    "|quantile |Compute sample quantile ranging from 0 to 1 (default: 0.5)|\n",
    "|sum |Sum of values|\n",
    "|mean |Mean of values|\n",
    "|median |Arithmetic median (50% quantile) of values|\n",
    "|mad |Mean absolute deviation from mean value|\n",
    "|prod |Product of all values|\n",
    "|var |Sample variance of values|\n",
    "|std |Sample standard deviation of values|\n",
    "|skew |Sample skewness (third moment) of values|\n",
    "|kurt |Sample kurtosis (fourth moment) of values|\n",
    "|cumsum |Cumulative sum of values|\n",
    "|cummin, cummax |Cumulative minimum or maximum of values, respectively|\n",
    "|cumprod |Cumulative product of values|\n",
    "|diff |Compute first arithmetic difference (useful for time series)|\n",
    "|pct_change |Compute percent changes|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum axis index: \n",
      "0    3.038738\n",
      "1   -3.537882\n",
      "2   -4.014652\n",
      "3    3.266265\n",
      "dtype: float64\n",
      "\n",
      "Sum axis columns: \n",
      "a    0.780806\n",
      "a    0.223444\n",
      "b   -0.167989\n",
      "c    1.075803\n",
      "d    0.086425\n",
      "e   -3.937496\n",
      "f    0.691476\n",
      "dtype: float64\n",
      "\n",
      "Basic Descriptive: \n",
      "              0         1         2         3\n",
      "count  7.000000  7.000000  7.000000  7.000000\n",
      "mean   0.434105 -0.505412 -0.573522  0.466609\n",
      "std    1.309310  0.570371  0.784796  0.990502\n",
      "min   -1.277837 -1.160491 -1.931288 -1.031637\n",
      "25%   -0.445086 -1.004174 -0.775543 -0.198882\n",
      "50%    0.271739 -0.434777 -0.631648  0.699623\n",
      "75%    1.391011 -0.141908 -0.224587  1.174842\n",
      "max    2.152987  0.349552  0.548543  1.646358\n",
      "\n",
      "Basic Descriptive 'd': \n",
      "count    4.000000\n",
      "mean     0.021606\n",
      "std      1.273140\n",
      "min     -1.277837\n",
      "25%     -0.793195\n",
      "50%     -0.141048\n",
      "75%      0.673753\n",
      "max      1.646358\n",
      "Name: d, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df = pd.DataFrame(np.random.standard_normal((7, 4)),\n",
    "                  index=[\"a\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "\n",
    "print(f\"Sum axis index: \\n{df.sum(axis='index')}\")\n",
    "print(f\"\\nSum axis columns: \\n{df.sum(axis='columns')}\")\n",
    "print(f\"\\nBasic Descriptive: \\n{df.describe()}\")\n",
    "print(f\"\\nBasic Descriptive 'd': \\n{df.loc['d'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Covariance\n",
    "\n",
    "The `corr()` method of Series computes the correlation of the overlapping, non-NA values in two Series, and `cov()` computes the covariance. With a Dataframe, `corr()` and `cov()` methodsreturn a full correlation or covariance matrix as a Dataframe. Using `corrwith()` method you can compute pair-wise correlations between a Dataframe's columns or rows with another Series or DF. Passing *axis=\"columns\"* compute row-by-row instead.\n",
    "<br>In all cases, the data points are aligned by label before the correlation is computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  AAPL        GOOG         IBM       MSFT\n",
      "Date                                                     \n",
      "2016-10-17  117.550003  779.960022  154.770004  57.220001\n",
      "2016-10-18  117.470001  795.260010  150.720001  57.660000\n",
      "2016-10-19  117.120003  801.500000  151.259995  57.529999\n",
      "2016-10-20  117.059998  796.969971  151.520004  57.250000\n",
      "2016-10-21  116.599998  799.369995  149.630005  59.660000\n",
      "\n",
      "Percentage change, last 5 rows: \n",
      "                AAPL      GOOG       IBM      MSFT\n",
      "Date                                              \n",
      "2016-10-17 -0.000680  0.001837  0.002072 -0.003483\n",
      "2016-10-18 -0.000681  0.019616 -0.026168  0.007690\n",
      "2016-10-19 -0.002979  0.007846  0.003583 -0.002255\n",
      "2016-10-20 -0.000512 -0.005652  0.001719 -0.004867\n",
      "2016-10-21 -0.003930  0.003011 -0.012474  0.042096\n",
      "\n",
      "Series: Apple x Google correlation in %-change:\n",
      "0.4079185761679699\n",
      "\n",
      "Correlation matrix: \n",
      "          AAPL      GOOG       IBM      MSFT\n",
      "AAPL  1.000000  0.407919  0.386817  0.389695\n",
      "GOOG  0.407919  1.000000  0.405099  0.465919\n",
      "IBM   0.386817  0.405099  1.000000  0.499764\n",
      "MSFT  0.389695  0.465919  0.499764  1.000000\n",
      "\n",
      "Correlation with other DF: \n",
      "AAPL   -0.075565\n",
      "GOOG   -0.007067\n",
      "IBM    -0.204849\n",
      "MSFT   -0.092950\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "price = pd.read_pickle(\"datasets/eg_yahoo_price.pkl\")\n",
    "volume = pd.read_pickle(\"datasets/eg_yahoo_volume.pkl\")\n",
    "\n",
    "print(price.tail())\n",
    "\n",
    "# Percentage Change\n",
    "returns = price.pct_change()\n",
    "print(f\"\\nPercentage change, last 5 rows: \\n{returns.tail()}\")\n",
    "\n",
    "# Correlation between two series\n",
    "print(f\"\\nSeries: Apple x Google correlation in %-change:\"\n",
    "      f\"\\n{returns['AAPL'].corr(returns['GOOG'])}\")\n",
    "\n",
    "print(f\"\\nCorrelation matrix: \\n{returns.corr()}\")\n",
    "\n",
    "print(f\"\\nCorrelation with other DF: \\n{returns.corrwith(volume)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values, Value counts, and Membership\n",
    "\n",
    "*Unique, value counts, and set membership methods*\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|isin |Compute a Boolean array indicating whether each Series or DataFrame value is contained in the passed sequence of values|\n",
    "|get_indexer |Compute integer indices for each value in an array into another array of distinct values; helpful for data alignment and join-type operations|\n",
    "|unique |Compute an array of unique values in a Series, returned in the order observed|\n",
    "|value_counts |Return a Series containing unique values as its index and frequencies as its values, ordered count in descending order|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values:\n",
      "['c' 'a' 'd' 'b']\n",
      "\n",
      "Value count: \n",
      "c    4\n",
      "a    4\n",
      "b    3\n",
      "d    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Using 'isin' to check whether or not a value is member of the Series:\n",
      "0      True\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8      True\n",
      "9      True\n",
      "10     True\n",
      "11    False\n",
      "dtype: bool\n",
      "\n",
      "Filtering with the last membership check: \n",
      "0     c\n",
      "5     b\n",
      "6     b\n",
      "7     c\n",
      "8     c\n",
      "9     b\n",
      "10    c\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"b\", \"c\", \"a\"])\n",
    "\n",
    "print(f\"Unique values:\\n{obj.unique()}\")\n",
    "print(f\"\\nValue count: \\n{obj.value_counts()}\")\n",
    "\n",
    "\"\"\"\n",
    "    We can check (True-False) membership of values in a Series with 'isin' \n",
    "    and use that as variable to filter\n",
    "\"\"\"\n",
    "\n",
    "borc = obj.isin([\"b\",\"c\"])\n",
    "\n",
    "print(f\"\\nUsing 'isin' to check whether or not a value is member of the Series:\"\n",
    "      f\"\\n{borc}\")\n",
    "\n",
    "print(f\"\\nFiltering with the last membership check: \\n{obj[borc]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c' 'a' 'd' 'b']\n",
      "[0 1 2 1 1 3 3 0 0 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"b\", \"c\", \"a\"])\n",
    "\n",
    "\"\"\"\n",
    "    the Index.get_indexer method gives you an index array from an array\n",
    "    of possibly nondistinct values into another array of distinct values\n",
    "\"\"\"\n",
    "\n",
    "print(obj.unique())\n",
    "\n",
    "unique_vals = obj.unique()\n",
    "# we can 'sort()' the variable 'unique_vals' to get alphabetical order\n",
    "\n",
    "# c=0 , a=1 , d=2 , b=3 : fast for to convert categories into numbers\n",
    "indices = pd.Index(unique_vals).get_indexer(obj)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qu2\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Index as values and the 'cells' is the count, filling 0: \n",
      "   Qu1  Qu2  Qu3\n",
      "1  1.0  1.0  1.0\n",
      "2  0.0  2.0  1.0\n",
      "3  2.0  2.0  0.0\n",
      "4  2.0  0.0  2.0\n",
      "5  0.0  0.0  1.0\n",
      "\n",
      "DataFrame2: \n",
      "   a  b\n",
      "0  1  0\n",
      "1  1  0\n",
      "2  1  1\n",
      "3  2  0\n",
      "4  2  0\n",
      "\n",
      "Value Counts, occurences of each distinct row:\n",
      "a  b\n",
      "1  0    2\n",
      "2  0    2\n",
      "1  1    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CursosTardes\\AppData\\Local\\Temp\\ipykernel_3996\\951299554.py:10: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  result = data.apply(pd.value_counts).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4],\n",
    "                     \"Qu2\": [2, 3, 1, 2, 3],\n",
    "                     \"Qu3\": [1, 5, 2, 4, 4]})\n",
    "\n",
    "print(data[\"Qu2\"].value_counts().sort_index())\n",
    "\n",
    "result = data.apply(pd.value_counts).fillna(0)\n",
    "print(f\"\\nIndex as values and the 'cells' is the count, filling 0: \\n{result}\")\n",
    "\n",
    "\"\"\"\n",
    "    DataFrame.value_counts() method compute counts considering each row\n",
    "    of the DataFrame as a tuple to determine the number of occurrences \n",
    "    of each dostinct row\n",
    "\"\"\"\n",
    "\n",
    "data2 = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\n",
    "\n",
    "print(f\"\\nDataFrame2: \\n{data2}\")\n",
    "\n",
    "print(f\"\\nValue Counts, occurences of each distinct row:\"\n",
    "      f\"\\n{data2.value_counts()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
