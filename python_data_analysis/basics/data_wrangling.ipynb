{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: join, combine, reshape\n",
    "\n",
    "In this chapter you will see tools to handle the data and make them suitable for analysis.\n",
    "\n",
    "## Index\n",
    "\n",
    "* [Hierarchical Indexing](#hierarchical-indexing)\n",
    "    * [Reordering and Sorting Levels](#reordering-and-sorting-levels)\n",
    "    * [Summary Statistics by Level](#summary-statistics-by-level)\n",
    "    * [Indexing with DataFrame's Columns](#indexing-with-dataframes-columns)\n",
    "* [Combining and Merging Datasets](#combining-and-merging-datasets)\n",
    "    * [Database-Style DataFrame Joins](#database-style-dataframe-joins)\n",
    "        * [Table: Pandas 'merge' arguments](#pandas-merge-function-arguments)\n",
    "    * [Merging on Index](#merging-on-index)\n",
    "        * ['join' method](#join-method)\n",
    "    * [Concatenating Along an Axis](#concatenating-along-an-axis)\n",
    "    * [Combining Data with Overlap](#combining-data-with-overlap)\n",
    "* [Reshaping and Pivoting](#reshaping-and-pivoting)\n",
    "    * [Reshaping with Hierachical Indexing](#reshaping-with-hierachical-indexing)\n",
    "    * [Pivoting 'Long' to 'Wide' Format](#pivoting-long-to-wide-format)\n",
    "        * [pivot method](#pivot-method)\n",
    "    * [Pivoting 'Wide' to 'Long' Format](#pivoting-wide-to-long-format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Indexing\n",
    "\n",
    "Hierarchical Indexing enables you to have multiple index levels on an axis. Also to work with high dimensional data in a lower dimensional form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  1    0.346664\n",
      "   2    0.140604\n",
      "   3    0.150648\n",
      "b  1    0.091401\n",
      "   3    0.003765\n",
      "c  1    0.754212\n",
      "   2    0.645723\n",
      "d  2    0.331423\n",
      "   3    0.369343\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Series with two index levels\n",
    "\n",
    "data = pd.Series(np.random.uniform(size=9), \n",
    "                 index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
    "                        [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('a', 1),\n",
      "            ('a', 2),\n",
      "            ('a', 3),\n",
      "            ('b', 1),\n",
      "            ('b', 3),\n",
      "            ('c', 1),\n",
      "            ('c', 2),\n",
      "            ('d', 2),\n",
      "            ('d', 3)],\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 'b' index: \n",
      "1    0.091401\n",
      "3    0.003765\n",
      "dtype: float64\n",
      "\n",
      "Data 'b' to 'c' index: \n",
      "b  1    0.091401\n",
      "   3    0.003765\n",
      "c  1    0.754212\n",
      "   2    0.645723\n",
      "dtype: float64\n",
      "\n",
      "Data 'b' and 'd' index: \n",
      "b  1    0.091401\n",
      "   3    0.003765\n",
      "d  2    0.331423\n",
      "   3    0.369343\n",
      "dtype: float64\n",
      "\n",
      "Data all value with 2 in second index: \n",
      "a    0.140604\n",
      "c    0.645723\n",
      "d    0.331423\n",
      "dtype: float64\n",
      "\n",
      "Data '1' and '3' from int index: \n",
      "a  2    0.140604\n",
      "b  1    0.091401\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data 'b' index: \\n{data['b']}\")\n",
    "print(f\"\\nData 'b' to 'c' index: \\n{data['b':'c']}\")\n",
    "print(f\"\\nData 'b' and 'd' index: \\n{data.loc[['b', 'd']]}\")\n",
    "print(f\"\\nData all value with 2 in second index: \\n{data.loc[:, 2]}\")\n",
    "print(f\"\\nData '1' and '3' from int index: \\n{data.iloc[[1, 3]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `unstack()` method to rearrange this Series into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstack data Series into a DataFrame: \n",
      "          1         2         3\n",
      "a  0.346664  0.140604  0.150648\n",
      "b  0.091401      <NA>  0.003765\n",
      "c  0.754212  0.645723      <NA>\n",
      "d      <NA>  0.331423  0.369343\n",
      "\n",
      "Stucking again the data: \n",
      "a  1    0.346664\n",
      "   2    0.140604\n",
      "   3    0.150648\n",
      "b  1    0.091401\n",
      "   3    0.003765\n",
      "c  1    0.754212\n",
      "   2    0.645723\n",
      "d  2    0.331423\n",
      "   3    0.369343\n",
      "dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "data = data.astype('Float64')\n",
    "print(f\"Unstack data Series into a DataFrame: \\n{data.unstack()}\")\n",
    "print(f\"\\nStucking again the data: \\n{data.unstack().stack()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a DataFrame, either axis can have a hierarchical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with 2 index in each axis: \n",
      "      z        x\n",
      "    red lime red\n",
      "a 1   0    1   2\n",
      "  2   3    4   5\n",
      "b 1   6    7   8\n",
      "  2   9   10  11\n"
     ]
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\n",
    "                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                     columns=[['z', 'z', 'x'], ['red', 'lime', 'red']])\n",
    "\n",
    "print(f\"DataFrame with 2 index in each axis: \\n{frame}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with names in its axis levels: \n",
      "omega       z        x\n",
      "color     red lime red\n",
      "key1 key2             \n",
      "a    1      0    1   2\n",
      "     2      3    4   5\n",
      "b    1      6    7   8\n",
      "     2      9   10  11\n",
      "\n",
      "DataFrame 'z' columns': \n",
      "color      red  lime\n",
      "key1 key2           \n",
      "a    1       0     1\n",
      "     2       3     4\n",
      "b    1       6     7\n",
      "     2       9    10\n",
      "\n",
      "DataFrame index 1: \n",
      "omega  color\n",
      "z      red      3\n",
      "       lime     4\n",
      "x      red      5\n",
      "Name: (a, 2), dtype: int32\n",
      "\n",
      "DataFrame 'a' and 'x' row: \n",
      "color  red\n",
      "key2      \n",
      "1        2\n",
      "2        5\n"
     ]
    }
   ],
   "source": [
    "# Naming the hierarchical levels:\n",
    "\n",
    "frame.index.names = ['key1', 'key2']\n",
    "frame.columns.names = ['omega', 'color']\n",
    "\n",
    "print(f\"DataFrame with names in its axis levels: \\n{frame}\")\n",
    "print(f\"\\nDataFrame 'z' columns': \\n{frame['z']}\")\n",
    "print(f\"\\nDataFrame index 1: \\n{frame.iloc[1]}\")\n",
    "print(f\"\\nDataFrame 'a' and 'x' row: \\n{frame.loc['a','x']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a MultiIndex:\n",
    "```python\n",
    "pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"],\n",
    "                           [\"Green\", \"Red\", \"Green\"]],\n",
    "                           names=[\"state\", \"color\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordering and Sorting Levels\n",
    "\n",
    "The swaplevel method returns a new object when we pass two level numbers or \n",
    "names and this levels will be interchanged.\n",
    "\n",
    "Also, `sort_index()` sort the index levels. Data selection performance is beter\n",
    "if index is sorted starting with the outermost level: `sort_index(level=0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swap level and sort 'key2':\n",
      "omega       z        x\n",
      "color     red lime red\n",
      "key2 key1             \n",
      "1    a      0    1   2\n",
      "     b      6    7   8\n",
      "2    a      3    4   5\n",
      "     b      9   10  11\n",
      "\n",
      "Swap level 0 and 1, filter '1' rows: \n",
      "omega   z        x\n",
      "color red lime red\n",
      "key1              \n",
      "a       0    1   2\n",
      "b       6    7   8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Swap level and sort 'key2':\"\n",
    "      f\"\\n{frame.swaplevel('key1', 'key2').sort_index(level=0)}\")\n",
    "\n",
    "print(f\"\\nSwap level 0 and 1, filter '1' rows: \"\n",
    "      f\"\\n{frame.swaplevel('key1', 'key2').loc[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics by Level\n",
    "\n",
    "Dataframes and Series have 'level' option in many descriptive and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>omega</th>\n",
       "      <th colspan=\"2\" halign=\"left\">z</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <th>red</th>\n",
       "      <th>lime</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "omega   z        x\n",
       "color red lime red\n",
       "key2              \n",
       "1       6    8  10\n",
       "2      12   14  16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.groupby(level='key2').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>lime</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">a</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">b</th>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "color      lime  red\n",
       "key1 key2           \n",
       "a    1        1    2\n",
       "     2        4    8\n",
       "b    1        7   14\n",
       "     2       10   20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.groupby(level='color', axis=\"columns\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing with DataFrame's Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b    c  d\n",
      "0  0  7  one  0\n",
      "1  1  6  one  1\n",
      "2  2  5  one  2\n",
      "3  3  4  two  0\n",
      "4  4  3  two  1\n",
      "5  5  2  two  2\n",
      "6  6  1  two  3\n"
     ]
    }
   ],
   "source": [
    "frame = pd.DataFrame({\"a\": range(7), \"b\": range(7, 0, -1),\n",
    "                      \"c\": [\"one\",\"one\",\"one\", \"two\",\"two\",\"two\",\"two\"],\n",
    "                      \"d\": [0, 1, 2, 0, 1, 2, 3]})\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select from the previous DataFrame one or more columns as the row index.\n",
    "Also, we can move the row index into the DataFrames columns:\n",
    "\n",
    "By default, the columns are removed but you can maintain it with `drop=Falsep`.\n",
    "An with `.reset_index()` to reset the index from `set_index()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frame2 Maintaining columns:\n",
      "       a  b    c  d\n",
      "c   d              \n",
      "one 0  0  7  one  0\n",
      "    1  1  6  one  1\n",
      "    2  2  5  one  2\n",
      "two 0  3  4  two  0\n",
      "    1  4  3  two  1\n",
      "    2  5  2  two  2\n",
      "    3  6  1  two  3\n",
      "\n",
      "Default set_index: \n",
      "       a  b\n",
      "c   d      \n",
      "one 0  0  7\n",
      "    1  1  6\n",
      "    2  2  5\n",
      "two 0  3  4\n",
      "    1  4  3\n",
      "    2  5  2\n",
      "    3  6  1\n",
      "\n",
      "Reset index from Frame2:\n",
      "     c  d  a  b\n",
      "0  one  0  0  7\n",
      "1  one  1  1  6\n",
      "2  one  2  2  5\n",
      "3  two  0  3  4\n",
      "4  two  1  4  3\n",
      "5  two  2  5  2\n",
      "6  two  3  6  1\n"
     ]
    }
   ],
   "source": [
    "frame2 = frame.set_index([\"c\", \"d\"], drop=False)\n",
    "print(f\"\\nFrame2 Maintaining columns:\\n{frame2}\")\n",
    "\n",
    "frame2 = frame.set_index([\"c\", \"d\"])\n",
    "print(f\"\\nDefault set_index: \\n{frame2}\")\n",
    "\n",
    "frame2 = frame2.reset_index()\n",
    "print(f\"\\nReset index from Frame2:\\n{frame2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining and Merging Datasets\n",
    "\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|`pandas.merge`|Connect rows in DataFrames based n one or more keys. Like `JOIN` in SQL.|\n",
    "|`pandas.concat`|Concatenate or \"stack\" objects toghether along an axis|\n",
    "|`combine_first`|Splice together overlapping data to fill in missing values in one object with values from another.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database-Style DataFrame Joins\n",
    "\n",
    "To combine datasets we can use `merge` or `join` operations by liking rows\n",
    "using one or more keys. With `merge()` we'll do *many-to-one* join, by default\n",
    "uses the overlapping column to identify the index (keys) but is a good\n",
    "practice to specify explicitly with `on=\"key\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame one: \n",
      "  key  data1\n",
      "0   b      0\n",
      "1   b      1\n",
      "2   a      2\n",
      "3   c      3\n",
      "4   a      4\n",
      "5   a      5\n",
      "6   b      6\n",
      "\n",
      "DataFrame two: \n",
      "  key  data2\n",
      "0   a      0\n",
      "1   b      1\n",
      "2   d      2\n",
      "\n",
      "DataFrame after 'merge': \n",
      "  key  data1  data2\n",
      "0   b      0      1\n",
      "1   b      1      1\n",
      "2   a      2      0\n",
      "3   a      4      0\n",
      "4   a      5      0\n",
      "5   b      6      1\n"
     ]
    }
   ],
   "source": [
    "df_one = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n",
    "                       \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
    "\n",
    "df_two = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"],\n",
    "                       \"data2\": pd.Series(range(3), dtype=\"Int64\")})\n",
    "\n",
    "print(f\"DataFrame one: \\n{df_one}\")\n",
    "print(f\"\\nDataFrame two: \\n{df_two}\")\n",
    "\n",
    "# Merging dataframes\n",
    "df_merge = pd.merge(df_one, df_two, on=\"key\")\n",
    "print(f\"\\nDataFrame after 'merge': \\n{df_merge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pandas `merge()` options for 'how=' argument:*\n",
    "|Option|Behavior|\n",
    "|---|---|\n",
    "|how=\"inner\" |Use only the key combinations observed in both tables|\n",
    "|how=\"left\" |Use all key combinations found in the left table|\n",
    "|how=\"right\" |Use all key combinations found in the right table|\n",
    "|how=\"outer\" |Use all key combinations observed in both tables together|\n",
    "\n",
    "With 'outer' option in 'how' argument takes the union of the keys, combining \n",
    "the effect of applying both left and right joins. By defaut `merge` does \n",
    "an \"inner\" join, which is the intersection or the common set \n",
    "found in both tables.\n",
    "\n",
    "And if the column names when we merge are diferentwe can specify them \n",
    "separetely with 'left_on=\"lkey\"' and 'right_on=\"rkey\"'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer join of DF_one and DF_two: \n",
      "  key  data1  data2\n",
      "0   a      2      0\n",
      "1   a      4      0\n",
      "2   a      5      0\n",
      "3   b      0      1\n",
      "4   b      1      1\n",
      "5   b      6      1\n",
      "6   c      3   <NA>\n",
      "7   d   <NA>      2\n",
      "\n",
      "Outer join (df_three + df_four) diferencing columns:\n",
      "  lkey  data1 rkey  data2\n",
      "0    a      2    a      0\n",
      "1    a      4    a      0\n",
      "2    a      5    a      0\n",
      "3    b      0    b      1\n",
      "4    b      1    b      1\n",
      "5    b      6    b      1\n",
      "6    c      3  NaN   <NA>\n",
      "7  NaN   <NA>    d      2\n"
     ]
    }
   ],
   "source": [
    "# Merging with outer-join\n",
    "df_merge_outer = pd.merge(df_one, df_two, how=\"outer\")\n",
    "\n",
    "print(f\"\\nOuter join of DF_one and DF_two: \\n{df_merge_outer}\")\n",
    "\n",
    "df_three = pd.DataFrame({\"lkey\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n",
    "                         \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
    "\n",
    "df_four = pd.DataFrame({\"rkey\": [\"a\", \"b\", \"d\"],\n",
    "                        \"data2\": pd.Series(range(3), dtype=\"Int64\")})\n",
    "\n",
    "df_merge = pd.merge(df_three, df_four, \n",
    "                    left_on=\"lkey\", right_on=\"rkey\",\n",
    "                    how=\"outer\")\n",
    "\n",
    "print(f\"\\nOuter join (df_three + df_four) diferencing columns:\"\n",
    "      f\"\\n{df_merge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Pandas `merge` function arguments*\n",
    "\n",
    "|Argument| Description|\n",
    "|---:|---|\n",
    "|left| DataFrame to be merged on the left side.|\n",
    "|right| DataFrame to be merged on the right side.|\n",
    "|how| Type of join to apply: one of \"inner\", \"outer\", \"left\", or \"right\"; defaults to \"inner\"|\n",
    "|on| Column names to join on. Must be found in both DataFrame objects. If not specified and no other join keys given, will use the intersection of the column names in left and right as the join keys.|\n",
    "|left_on| Columns in left DataFrame to use as join keys. Can be a single column name or a list of column names.|\n",
    "|right_on| Analogous to left_on for right DataFrame.|\n",
    "|left_index| Use row index in left as its join key (or keys, if a MultiIndex).|\n",
    "|right_index| Analogous to left_index.|\n",
    "|sort| Sort merged data lexicographically by join keys; False by default.|\n",
    "|suffixes| Tuple of string values to append to column names in case of overlap; defaults to (\"_x\", \"_y\") (e.g., if \"data\" in both DataFrame objects, would appear as \"data_x\" and \"data_y\" in result).|\n",
    "|copy| If False, avoid copying data into resulting data structure in some exceptional cases; by default always copies.|\n",
    "|validate| Verifies if the merge is of the specified type, whether one-to-one, one-to-many, or many-to-many. See the docstring for full details on the options.|\n",
    "|indicator| Adds a special column _merge that indicates the source of each row; values will be \"left_only\", \"right_only\", or \"both\" based on the origin of the joined data in each row.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merge with left Join: \n",
      "   key  data1  data2\n",
      "0    b      0      1\n",
      "1    b      0      3\n",
      "2    b      1      1\n",
      "3    b      1      3\n",
      "4    a      2      0\n",
      "5    a      2      2\n",
      "6    c      3   <NA>\n",
      "7    a      4      0\n",
      "8    a      4      2\n",
      "9    b      5      1\n",
      "10   b      5      3\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"],\n",
    "                     \"data1\": pd.Series(range(6), dtype=\"Int64\")})\n",
    "df_2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"b\", \"d\"],\n",
    "                     \"data2\": pd.Series(range(5), dtype=\"Int64\")})\n",
    "\n",
    "# Left JOIN (df_1 + df_2)\n",
    "df_merge = pd.merge(df_1, df_2, on=\"key\", how=\"left\")\n",
    "print(f\"\\nMerge with left Join: \\n{df_merge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging with two keys and Outer Join: \n",
      "  key1 key2  lval  rval\n",
      "0  bar  one     3     6\n",
      "1  bar  two  <NA>     7\n",
      "2  foo  one     1     4\n",
      "3  foo  one     1     5\n",
      "4  foo  two     2  <NA>\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\"],\n",
    "                     \"key2\": [\"one\", \"two\", \"one\"],\n",
    "                     \"lval\": pd.Series([1, 2, 3], dtype='Int64')})\n",
    "right = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\", \"bar\"],\n",
    "                     \"key2\": [\"one\", \"one\", \"one\", \"two\"],\n",
    "                     \"rval\": pd.Series([4, 5, 6, 7], dtype='Int64')})\n",
    "\n",
    "# Merge with multiple keys using a list of names\n",
    "\n",
    "df_merge_lr = pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"outer\")\n",
    "\n",
    "print(f\"\\nMerging with two keys and Outer Join: \\n{df_merge_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we join columns on columns the indexes on the pased DataFrame objects \n",
    "are discarded. To preserve the index values use `reset_index` to append \n",
    "the index to the columns.\n",
    "\n",
    "Merging one column (overlap it) but with other column with the same name in both datasets\n",
    "pandas will generate a sufix (_x and _y by default), we can specify the suffix\n",
    "with `suffixes=(\"_left\", \"_right\")` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2_left</th>\n",
       "      <th>lval</th>\n",
       "      <th>key2_right</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "      <td>one</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "      <td>one</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>3</td>\n",
       "      <td>one</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>3</td>\n",
       "      <td>two</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key1 key2_left  lval key2_right  rval\n",
       "0  foo       one     1        one     4\n",
       "1  foo       one     1        one     5\n",
       "2  foo       two     2        one     4\n",
       "3  foo       two     2        one     5\n",
       "4  bar       one     3        one     6\n",
       "5  bar       one     3        two     7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left, right, on=\"key1\", suffixes=(\"_left\", \"_right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on Index\n",
    "\n",
    "When we are merging we can select from which DataFrame use the index, to do\n",
    "this we can pass `left_index=True` or `right_index=True` (or both) to indicate\n",
    "that the indes should be used as the merge keys.\n",
    "\n",
    "Remember, by default merge use Inner Join (how='inner'), then it will preserve \n",
    "the rows with index that match with our selection.\n",
    "\n",
    "Joining with hierarchically indexed data is equivalent to a multiple-key merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DataFrame: \n",
      "  key  value\n",
      "0   a      0\n",
      "1   b      1\n",
      "2   a      2\n",
      "3   a      3\n",
      "4   b      4\n",
      "5   c      5\n",
      "\n",
      "Second DataFrame: \n",
      "   group_val\n",
      "a        3.5\n",
      "b        7.0\n",
      "\n",
      "Merging with right index:\n",
      "   key  value  group_val\n",
      "0   a      0        3.5\n",
      "1   b      1        7.0\n",
      "2   a      2        3.5\n",
      "3   a      3        3.5\n",
      "4   b      4        7.0\n"
     ]
    }
   ],
   "source": [
    "left1 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"c\"],\n",
    "                      \"value\": pd.Series(range(6), dtype=\"Int64\")})\n",
    "right1 = pd.DataFrame({\"group_val\": [3.5, 7]}, index=[\"a\", \"b\"])\n",
    "\n",
    "print(f\"First DataFrame: \\n{left1}\\n\"\n",
    "      f\"\\nSecond DataFrame: \\n{right1}\")\n",
    "\n",
    "# Merging and specify right index\n",
    "print(f\"\\nMerging with right index:\\n\",\n",
    "      pd.merge(left1, right1, left_on=\"key\", right_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left DataFrame: \n",
      "     key1  key2  data\n",
      "0    Ohio  2000     0\n",
      "1    Ohio  2001     1\n",
      "2    Ohio  2002     2\n",
      "3  Nevada  2001     3\n",
      "4  Nevada  2002     4\n",
      "\n",
      "Right DataFrame: \n",
      "             event1  event2\n",
      "Nevada 2001       0       1\n",
      "       2000       2       3\n",
      "Ohio   2000       4       5\n",
      "       2000       6       7\n",
      "       2001       8       9\n",
      "       2002      10      11\n"
     ]
    }
   ],
   "source": [
    "lefth = pd.DataFrame({\"key1\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\"],\n",
    "                      \"key2\": [2000, 2001, 2002, 2001, 2002],\n",
    "                      \"data\": pd.Series(range(5), dtype=\"Int64\")})\n",
    "\n",
    "righth_index = pd.MultiIndex.from_arrays(\n",
    "                    [\n",
    "                        [\"Nevada\", \"Nevada\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\"],\n",
    "                        [2001, 2000, 2000, 2000, 2001, 2002]\n",
    "                    ]\n",
    "               )\n",
    "righth = pd.DataFrame({\"event1\": pd.Series([0, 2, 4, 6, 8, 10], dtype=\"Int64\",\n",
    "                                           index=righth_index),\n",
    "                       \"event2\": pd.Series([1, 3, 5, 7, 9, 11], dtype=\"Int64\",\n",
    "                                           index=righth_index)})\n",
    "\n",
    "print(f\"Left DataFrame: \\n{lefth}\\n\"\n",
    "      f\"\\nRight DataFrame: \\n{righth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge with right index and Outer Join:\n",
      "     key1  key2  data  event1  event2\n",
      "4  Nevada  2000  <NA>       2       3\n",
      "3  Nevada  2001     3       0       1\n",
      "4  Nevada  2002     4    <NA>    <NA>\n",
      "0    Ohio  2000     0       4       5\n",
      "0    Ohio  2000     0       6       7\n",
      "1    Ohio  2001     1       8       9\n",
      "2    Ohio  2002     2      10      11\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    We have to indicate multiple columns to merge on as a list because \n",
    "    in this case the DataFrames have multiple index.\n",
    "\"\"\"\n",
    "\n",
    "mergedh = pd.merge(lefth, righth, left_on=[\"key1\", \"key2\"], \n",
    "                   right_index=True, how=\"outer\")\n",
    "print(f\"Merge with right index and Outer Join:\\n{mergedh}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `join()` Method\n",
    "\n",
    "The `join()` method simplify merging by index, we can combine DataFrame objects\n",
    "having the same or similar indexes but non-overlapping. Compare with `merge()`,\n",
    "`join` performs a **left join on the join keys by default**.\n",
    "\n",
    "Joining data *into* the object whose `join` method was called it's joinining \n",
    "the index of the passed DataFrame on one of the columns \n",
    "of the calling DataFrame. Also, you can pass a list of DataFrames with join\n",
    "as an alternative to using `pandas.concat()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge using both left_ right_index as True and Outer Join:\n",
      "   Ohio  Nevada  Missouri  Alabama\n",
      "a     1       2      <NA>     <NA>\n",
      "b  <NA>    <NA>         7        8\n",
      "c     3       4         9       10\n",
      "d  <NA>    <NA>        11       12\n",
      "e     5       6        13       14\n",
      "\n",
      "Alternative using 'join()' return the same result:\n",
      "    Ohio  Nevada  Missouri  Alabama\n",
      "a     1       2      <NA>     <NA>\n",
      "b  <NA>    <NA>         7        8\n",
      "c     3       4         9       10\n",
      "d  <NA>    <NA>        11       12\n",
      "e     5       6        13       14\n",
      "\n",
      "'join()' but specify 'on' key:\n",
      "   key  value  group_val\n",
      "0   a      0        3.5\n",
      "1   b      1        7.0\n",
      "2   a      2        3.5\n",
      "3   a      3        3.5\n",
      "4   b      4        7.0\n",
      "5   c      5        NaN\n"
     ]
    }
   ],
   "source": [
    "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],\n",
    "                    index=[\"a\", \"c\", \"e\"],\n",
    "                    columns=[\"Ohio\", \"Nevada\"]).astype(\"Int64\")\n",
    "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
    "                    index=[\"b\", \"c\", \"d\", \"e\"],\n",
    "                    columns=[\"Missouri\", \"Alabama\"]).astype(\"Int64\")\n",
    "mergel2r2 = pd.merge(left2, right2, how=\"outer\", \n",
    "                     left_index=True, right_index=True)\n",
    "print(f\"Merge using both left_ right_index as True and Outer Join:\"\n",
    "      f\"\\n{mergel2r2}\")\n",
    "\n",
    "print(f\"\\nAlternative using 'join()' return the same result:\\n\",\n",
    "      left2.join(right2, how=\"outer\"))\n",
    "\n",
    "print(f\"\\n'join()' but specify 'on' key:\\n\",\n",
    "      left1.join(right1, on=\"key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra DataFrame: \n",
      "   New York  Oregon\n",
      "a       7.0     8.0\n",
      "c       9.0    10.0\n",
      "e      11.0    12.0\n",
      "f      16.0    17.0\n",
      "\n",
      "'join()' with a list of DataFrames\n",
      "   Ohio  Nevada  Missouri  Alabama  New York  Oregon\n",
      "a     1       2      <NA>     <NA>       7.0     8.0\n",
      "c     3       4         9       10       9.0    10.0\n",
      "e     5       6        13       14      11.0    12.0\n",
      "\n",
      "   Ohio  Nevada  Missouri  Alabama  New York  Oregon\n",
      "a     1       2      <NA>     <NA>       7.0     8.0\n",
      "c     3       4         9       10       9.0    10.0\n",
      "e     5       6        13       14      11.0    12.0\n",
      "b  <NA>    <NA>         7        8       NaN     NaN\n",
      "d  <NA>    <NA>        11       12       NaN     NaN\n",
      "f  <NA>    <NA>      <NA>     <NA>      16.0    17.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    And lastly, using 'join()' with a list of DataFrames\n",
    "\"\"\"\n",
    "\n",
    "right_other = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
    "                            index=[\"a\", \"c\", \"e\", \"f\"],\n",
    "                            columns=[\"New York\", \"Oregon\"])\n",
    "\n",
    "print(f\"Extra DataFrame: \\n{right_other}\")\n",
    "\n",
    "print(f\"\\n'join()' with a list of DataFrames\\n\",\n",
    "      left2.join([right2, right_other]), \"\\n\\n\",\n",
    "      left2.join([right2, right_other], how=\"outer\"), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Along an Axis\n",
    "\n",
    "Concatenate is called 'stacking' too. NumPy can concatenate arrays \n",
    "with `numpy.concatenate()`. \n",
    "\n",
    "Pandas have `concat()` function which cares about what to do if the objects are\n",
    "indexed differently, if the chunks of concatenated data have to be \n",
    "identifiable, and if the axis contain data that need to be preserved. \n",
    "By default `concat()` works in 'index' axis, but we can use 'axis' argument and\n",
    "specify \"columns\", this it will create a DataFrame. When we use the \"columns\"\n",
    "axis is like a 'outer join' of the indexes (without overlap).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`concat` function arguments*\n",
    "\n",
    "|Argument| Description|\n",
    "|---:|----|\n",
    "|objs |List or dictionary of pandas objects to be concatenated; this is the only required argument|\n",
    "|axis |Axis to concatenate along; defaults to concatenating along rows (axis=\"index\")|\n",
    "|join |Either \"inner\" or \"outer\" (\"outer\" by default); whether to intersect (inner) or union (outer) indexes along the other axes|\n",
    "|keys |Values to associate with objects being concatenated, forming a hierarchical index along the concatenation axis; can be a list or array of arbitrary values, an array of tuples, or a list of arrays (if multiple-level arrays passed in levels)|\n",
    "|levels |Specific indexes to use as hierarchical index level or levels if keys passed|\n",
    "|names |Names for created hierarchical levels if keys and/or levels passed|\n",
    "|verify_integrity |Check new axis in concatenated object for duplicates and raise an exception if so; by default (False) allows duplicates|\n",
    "|ignore_index |Do not preserve indexes along concatenation axis, instead produce a new range(total_length) index|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three series concatenated:\n",
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "f    5\n",
      "g    6\n",
      "dtype: Int64\n",
      "\n",
      "Three series concatenated on axis columns:\n",
      "      0     1     2\n",
      "a     0  <NA>  <NA>\n",
      "b     1  <NA>  <NA>\n",
      "c  <NA>     2  <NA>\n",
      "d  <NA>     3  <NA>\n",
      "e  <NA>     4  <NA>\n",
      "f  <NA>  <NA>     5\n",
      "g  <NA>  <NA>     6\n",
      "\n",
      "Concatenating Series1 and Series4 on columns:\n",
      "      0  1\n",
      "a     0  0\n",
      "b     1  1\n",
      "f  <NA>  5\n",
      "g  <NA>  6\n",
      "\n",
      "Concatenating Series1 and Series4 on columns with 'inner join':\n",
      "   0  1\n",
      "a  0  0\n",
      "b  1  1\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series([0, 1], index=[\"a\", \"b\"], dtype=\"Int64\")\n",
    "ser2 = pd.Series([2, 3, 4], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\n",
    "ser3 = pd.Series([5, 6], index=[\"f\", \"g\"], dtype=\"Int64\")\n",
    "ser4 = pd.concat([ser1, ser3])\n",
    "\n",
    "# Concatenating series\n",
    "print(f\"Three series concatenated:\\n\",\n",
    "      pd.concat([ser1, ser2, ser3]), sep='')\n",
    "\n",
    "print(f\"\\nThree series concatenated on axis columns:\\n\",\n",
    "      pd.concat([ser1, ser2, ser3], axis=\"columns\"), sep='')\n",
    "\n",
    "print(f\"\\nConcatenating Series1 and Series4 on columns:\\n\",\n",
    "      pd.concat([ser1, ser4], axis=\"columns\"), sep='')\n",
    "\n",
    "print(f\"\\nConcatenating Series1 and Series4 on columns with 'inner join':\\n\",\n",
    "      pd.concat([ser1, ser4], axis=\"columns\", join=\"inner\"), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat options\n",
    "\n",
    "When we concat specifying \"keys\" argument, it will concat and use this 'keys' \n",
    "as second index but if we pass \"columns\" as axis will use the 'keys' as \n",
    "column names. In a DataFrame it follows the same logic, it will use 'keys' like\n",
    "a second level of \"columns\" axis in a hierarchical index which help us to\n",
    "identify each of the concatenated DataFrame. Alternatively we can pass intead\n",
    "of a list of DataFrame a Dictionary and it will use the dictionary keys as\n",
    "the keys argument. The 'names' argument allow us to named the created axis \n",
    "levels.\n",
    "\n",
    "If the index of a DataFrame have not relevant data, we can pass\n",
    "'ignore_index=True' argument to concatenate the data in the columns only, and\n",
    "the concatenation will asign a new default index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concat with 'keys' argument as hierarchical index:\n",
      "one    a    0\n",
      "       b    1\n",
      "two    a    0\n",
      "       b    1\n",
      "three  f    5\n",
      "       g    6\n",
      "four   a    0\n",
      "       b    1\n",
      "       f    5\n",
      "       g    6\n",
      "dtype: Int64\n",
      "\n",
      "Unstacking the result:\n",
      "          a     b     f     g\n",
      "one       0     1  <NA>  <NA>\n",
      "two       0     1  <NA>  <NA>\n",
      "three  <NA>  <NA>     5     6\n",
      "four      0     1     5     6\n",
      "\n",
      "Concat with 'keys' argument and 'columns' axis:\n",
      "    one   two  three  four\n",
      "a     0     0   <NA>     0\n",
      "b     1     1   <NA>     1\n",
      "f  <NA>  <NA>      5     5\n",
      "g  <NA>  <NA>      6     6\n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([ser1, ser1, ser3, ser4], \n",
    "                   keys=[\"one\", \"two\", \"three\", \"four\"])\n",
    "\n",
    "result_col = pd.concat([ser1, ser1, ser3, ser4], \n",
    "                   keys=[\"one\", \"two\", \"three\", \"four\"], axis=\"columns\")\n",
    "\n",
    "print(f\"\\nConcat with 'keys' argument as hierarchical index:\\n\",\n",
    "      result,\"\\n\\nUnstacking the result:\\n\", result.unstack(), sep='')\n",
    "\n",
    "print(f\"\\nConcat with 'keys' argument and 'columns' axis:\\n\",\n",
    "      result_col, sep='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames:\n",
      "    one  two\n",
      "a    0    1\n",
      "b    2    3\n",
      "c    4    5\n",
      "d    6    7 \n",
      "\n",
      "    three  four\n",
      "a      7     8\n",
      "c      9    10\n",
      "d     11    12\n",
      "\n",
      "Concatenated DataFrame:\n",
      "  level1     level2      \n",
      "     one two  three  four\n",
      "a      0   1      7     8\n",
      "b      2   3   <NA>  <NA>\n",
      "c      4   5      9    10\n",
      "d      6   7     11    12\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.arange(8).reshape(4, 2), index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "        columns=[\"one\", \"two\"], dtype=\"Int64\")\n",
    "df2 = pd.DataFrame(7 + np.arange(6).reshape(3, 2), index=[\"a\", \"c\", \"d\"],\n",
    "        columns=[\"three\", \"four\"], dtype=\"Int64\")\n",
    "\n",
    "print(f\"DataFrames:\\n\", df1, \"\\n\\n\", df2)\n",
    "\n",
    "print(f\"\\nConcatenated DataFrame:\\n\",\n",
    "      pd.concat([df1, df2], axis=\"columns\", keys=[\"level1\", \"level2\"]), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenated DataFrame using dictionary instead of 'keys' option:\n",
      "and adding 'names' argument to name the columns levels:\n",
      "\n",
      "upper level1     level2      \n",
      "lower    one two  three  four\n",
      "a          0   1      7     8\n",
      "b          2   3   <NA>  <NA>\n",
      "c          4   5      9    10\n",
      "d          6   7     11    12\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nConcatenated DataFrame using dictionary instead of 'keys' option:\\n\",\n",
    "      \"and adding 'names' argument to name the columns levels:\\n\\n\",\n",
    "      pd.concat({\"level1\": df1, \"level2\": df2}, \n",
    "                axis=\"columns\", names=[\"upper\", \"lower\"]),\n",
    "      sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DataFrame:\n",
      "          a         b         c         d\n",
      "0  0.235196  0.264797  0.278396 -0.216948\n",
      "1 -0.821781 -0.785710  1.219959  1.517616\n",
      "2  0.459172  1.603130 -0.482889  0.434575\n",
      "\n",
      "Second DataFrame:\n",
      "          b         d         a\n",
      "0 -0.557042 -1.103028 -0.552315\n",
      "1  2.795264  0.685565  0.211977\n",
      "\n",
      "Concatenating DataFrames but ignored non-important index:\n",
      "          a         b         c         d\n",
      "0  0.235196  0.264797  0.278396 -0.216948\n",
      "1 -0.821781 -0.785710  1.219959  1.517616\n",
      "2  0.459172  1.603130 -0.482889  0.434575\n",
      "3 -0.552315 -0.557042       NaN -1.103028\n",
      "4  0.211977  2.795264       NaN  0.685565\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.random.standard_normal((3, 4)),\n",
    "                   columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "df2 = pd.DataFrame(np.random.standard_normal((2, 3)),\n",
    "                   columns=[\"b\", \"d\", \"a\"])\n",
    "\n",
    "print(f\"First DataFrame:\\n\", df1, sep='')\n",
    "print(f\"\\nSecond DataFrame:\\n\", df2, sep='')\n",
    "\n",
    "print(f\"\\nConcatenating DataFrames but ignored non-important index:\\n\", \n",
    "      pd.concat([df1, df2], ignore_index=True), sep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Data with Overlap\n",
    "\n",
    "If we have two Series with an index mostly shared but with NaN values, we can\n",
    "use function `combine_first()` to combine the values of one Series with other. \n",
    "`combine_first` line up values by index.\n",
    "Also works in DataFrames in which case will combine columns. This method takes\n",
    "one column or series and will fill NaN values with the other column from\n",
    "the second DataFrame matching the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series 'a': \n",
      "f    NaN\n",
      "e    2.5\n",
      "d    0.0\n",
      "c    3.5\n",
      "b    4.5\n",
      "a    NaN\n",
      "dtype: float64\n",
      "\n",
      "Series 'b': \n",
      "a    0.0\n",
      "b    NaN\n",
      "c    2.0\n",
      "d    NaN\n",
      "e    NaN\n",
      "f    5.0\n",
      "dtype: float64\n",
      "\n",
      "Combining Series 'a' NaN values with matching Series 'b' values: \n",
      "a    0.0\n",
      "b    4.5\n",
      "c    3.5\n",
      "d    0.0\n",
      "e    2.5\n",
      "f    5.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "a = pd.Series([np.nan, 2.5, 0.0, 3.5, 4.5, np.nan],\n",
    "                index=[\"f\", \"e\", \"d\", \"c\", \"b\", \"a\"])\n",
    "b = pd.Series([0., np.nan, 2., np.nan, np.nan, 5.],\n",
    "                index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "\n",
    "print(f\"\\nSeries 'a': \\n{a}\", sep='')\n",
    "print(f\"\\nSeries 'b': \\n{b}\", sep='')\n",
    "print(f\"\\nCombining Series 'a' NaN values with matching Series 'b' values: \",\n",
    "      f\"\\n{a.combine_first(b)}\", sep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Pivoting\n",
    "\n",
    "### Reshaping with Hierachical Indexing\n",
    "\n",
    "- stack: rotates or pivots from the columns in the data to the rows.\n",
    "- unstack: pivots from the rows into the columns.\n",
    "\n",
    "You can `unstack` using the level number or level index name. But might \n",
    "introduce some NaN values if this values are not found in each subgroup. If\n",
    "there are various levels, the level unstacked becomes the lowerst level in \n",
    "the result. As with unstack, when calling stack we can indicate the name of \n",
    "the axis to stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "number    one  two  three\n",
      "state                    \n",
      "Ohio        0    1      2\n",
      "Colorado    3    4      5\n",
      "\n",
      "DataFrame with 'stack()' is like a Series: \n",
      "state     number\n",
      "Ohio      one       0\n",
      "          two       1\n",
      "          three     2\n",
      "Colorado  one       3\n",
      "          two       4\n",
      "          three     5\n",
      "dtype: int32\n",
      "\n",
      "'unstack()' recover DF the shape but in level 0:\n",
      "state   Ohio  Colorado\n",
      "number                \n",
      "one        0         3\n",
      "two        1         4\n",
      "three      2         5\n",
      "\n",
      "'unstack()' recover DF the shape passing level 'state':\n",
      "state   Ohio  Colorado\n",
      "number                \n",
      "one        0         3\n",
      "two        1         4\n",
      "three      2         5\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
    "                    index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n",
    "                    columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\n",
    "\n",
    "print(f\"DataFrame:\\n\", data, sep='')\n",
    "\n",
    "data_stack = data.stack()\n",
    "\n",
    "print(f\"\\nDataFrame with 'stack()' is like a Series: \\n\",\n",
    "      data_stack, sep='')\n",
    "\n",
    "# Unstacking on level 0\n",
    "print(\"\\n'unstack()' recover DF the shape but in level 0:\\n\", \n",
    "      data_stack.unstack(level=0), sep='')\n",
    "print(\"\\n'unstack()' recover DF the shape passing level 'state':\\n\", \n",
    "      data_stack.unstack(level=\"state\"), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Series:\n",
      "one  a    0\n",
      "     b    1\n",
      "     c    2\n",
      "     d    3\n",
      "two  c    4\n",
      "     d    5\n",
      "     e    6\n",
      "dtype: Int64\n",
      "\n",
      "Series unstacked:\n",
      "        a     b  c  d     e\n",
      "one     0     1  2  3  <NA>\n",
      "two  <NA>  <NA>  4  5     6\n",
      "\n",
      "Series unstacked:\n",
      "one  a       0\n",
      "     b       1\n",
      "     c       2\n",
      "     d       3\n",
      "     e    <NA>\n",
      "two  a    <NA>\n",
      "     b    <NA>\n",
      "     c       4\n",
      "     d       5\n",
      "     e       6\n",
      "dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    'unstack' a series which introduce some NaN values.\n",
    "\"\"\"\n",
    "\n",
    "ser1 = pd.Series([0, 1, 2, 3], index=[\"a\", \"b\", \"c\", \"d\"], dtype=\"Int64\")\n",
    "ser2 = pd.Series([4, 5, 6], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\n",
    "data2 = pd.concat([ser1, ser2], keys=[\"one\", \"two\"])\n",
    "\n",
    "print(\"Concatenated Series:\\n\", data2, sep='')\n",
    "print(\"\\nSeries unstacked:\\n\", data2.unstack(), sep='')\n",
    "\n",
    "#\n",
    "# Stacking the data2.unstack() with 'dropna=False' option will show us\n",
    "# the previous NaN values, thus equating the index of both chunks\n",
    "#\n",
    "\n",
    "print(\"\\nSeries unstacked:\\n\", data2.unstack().stack(dropna=False), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "side             left  right\n",
      "state    number             \n",
      "Ohio     one        0      5\n",
      "         two        1      6\n",
      "         three      2      7\n",
      "Colorado one        3      8\n",
      "         two        4      9\n",
      "         three      5     10\n",
      "\n",
      " Unstacked DataFrame, level=state: \n",
      "side   left          right         \n",
      "state  Ohio Colorado  Ohio Colorado\n",
      "number                             \n",
      "one       0        3     5        8\n",
      "two       1        4     6        9\n",
      "three     2        5     7       10\n",
      "\n",
      "Stack DataFrame again but passing level='side'\n",
      "state         Ohio  Colorado\n",
      "number side                 \n",
      "one    left      0         3\n",
      "       right     5         8\n",
      "two    left      1         4\n",
      "       right     6         9\n",
      "three  left      2         5\n",
      "       right     7        10\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    DataFrame with multiple hierarchical levels will unstack passing the level\n",
    "    number or level name, it'll be unstacked the lowest level in the result.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame({\"left\": data_stack, \"right\": data_stack + 5},\n",
    "                   columns=pd.Index([\"left\", \"right\"], name=\"side\"))\n",
    "\n",
    "print(\"DataFrame:\\n\", df, sep='')\n",
    "print(\"\\n Unstacked DataFrame, level=state: \\n\", df.unstack(level=\"state\"),\n",
    "      sep='')\n",
    "\n",
    "print(\"\\nStack DataFrame again but passing level='side'\\n\", \n",
    "      df.unstack(level=\"state\").stack(level=\"side\"),\n",
    "      sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting 'Long' to 'Wide' Format\n",
    "\n",
    "In long or stacked format, the individual values are represented by a single \n",
    "row in a table rather tahn multiple values per row.\n",
    "\n",
    "Dataset:\n",
    "https://github.com/wesm/pydata-book/blob/3rd-edition/examples/macrodata.csv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sample:\n",
      "     year  quarter    realgdp   infl  unemp\n",
      "155  1997        4  10008.874   1.24    4.7\n",
      "2    1959        3   2775.488   2.74    5.3\n",
      "95   1982        4   5871.001  -0.82   10.7\n",
      "23   1964        4   3431.957   2.05    5.0\n",
      "74   1977        3   5451.921   5.23    6.9\n",
      "84   1980        1   5908.467  14.60    6.3\n",
      "163  1999        4  11014.254   2.85    4.1\n",
      "53   1972        2   4633.101   2.88    5.7\n",
      "\n",
      "Periods of time extracted from dataset:\n",
      "PeriodIndex(['1959Q1', '1959Q2', '1959Q3', '1959Q4', '1960Q1', '1960Q2',\n",
      "             '1960Q3'],\n",
      "            dtype='period[Q-DEC]', name='date')\n",
      "\n",
      "DataFrame sample, index updated and column name:\n",
      "item          realgdp  unemp  infl\n",
      "date                              \n",
      "1986-10-01   7153.359    6.8  4.33\n",
      "1962-01-01   3031.241    5.6  2.26\n",
      "1972-04-01   4633.101    5.7  2.88\n",
      "1991-01-01   7950.164    6.6  1.19\n",
      "1972-10-01   4754.546    5.3  4.71\n",
      "1998-01-01  10103.425    4.6  0.49\n",
      "1991-10-01   8069.046    7.1  3.19\n",
      "1993-10-01   8643.769    6.6  1.92\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/macrodata.csv\")\n",
    "data = data.loc[:, [\"year\", \"quarter\", \"realgdp\", \"infl\", \"unemp\"]]\n",
    "\n",
    "print(\"DataFrame sample:\\n\", data.sample(8), sep='')\n",
    "\n",
    "\"\"\"\n",
    "    Extracting time periods, combining 'year' and 'quarter' columns\n",
    "    resulting in datetime values as 'date' column name. Then, unsing the new\n",
    "    'date' values as index for the DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "periods = pd.PeriodIndex(year=data.pop(\"year\"),\n",
    "                         quarter=data.pop(\"quarter\"),\n",
    "                         name=\"date\")\n",
    "print(\"\\nPeriods of time extracted from dataset:\\n\", periods[:7], sep='')\n",
    "# First 7 values from 'periods' \n",
    "\n",
    "# Using 'periods' as index in the DataFrame\n",
    "data.index = periods.to_timestamp(\"D\")\n",
    "\n",
    "\"\"\"\n",
    "    Reindexing and ordering columns and giving it a 'item' name for that index.\n",
    "\"\"\"\n",
    "\n",
    "data = data.reindex(columns=[\"realgdp\", \"unemp\", \"infl\"])\n",
    "data.columns.name = \"item\"\n",
    "\n",
    "print(\"\\nDataFrame sample, index updated and column name:\\n\",\n",
    "      data.sample(8), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 9 rows from Data in long format:\n",
      "\n",
      "         date     item     value\n",
      "0 1959-01-01  realgdp  2710.349\n",
      "1 1959-01-01    unemp     5.800\n",
      "2 1959-01-01     infl     0.000\n",
      "3 1959-04-01  realgdp  2778.801\n",
      "4 1959-04-01    unemp     5.100\n",
      "5 1959-04-01     infl     2.340\n",
      "6 1959-07-01  realgdp  2775.488\n",
      "7 1959-07-01    unemp     5.300\n",
      "8 1959-07-01     infl     2.740\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Reshaping 'data' to long format with 'stack()' and turning the index levels\n",
    "    into columns with reset_index. Also giving to the data column 'value' name.\n",
    "\"\"\"\n",
    "\n",
    "long_data = (data.stack()\n",
    "             .reset_index()\n",
    "             .rename(columns={0: \"value\"}))\n",
    "\n",
    "print(\"First 9 rows from Data in long format:\\n\\n\", long_data[:9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pivot method\n",
    "\n",
    "Sometimes in relational databases the data is stored this way. In some cases\n",
    "this long format may be more dificult and we might prefer to have a DataFrame\n",
    "containing one column per distinct item and indexed by timestamps. With \n",
    "DataFrame `pivot` method do this transformation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted long format Data:\n",
      "item        infl   realgdp  unemp\n",
      "date                             \n",
      "1959-01-01  0.00  2710.349    5.8\n",
      "1959-04-01  2.34  2778.801    5.1\n",
      "1959-07-01  2.74  2775.488    5.3\n",
      "1959-10-01  0.27  2785.204    5.6\n",
      "1960-01-01  2.31  2847.699    5.2\n",
      "\n",
      "Long Data with new column:\n",
      "           date     item     value    value2\n",
      "218 1977-01-01     infl     8.760 -0.964067\n",
      "345 1987-10-01  realgdp  7458.022  0.543163\n",
      "276 1982-01-01  realgdp  5857.333  0.103318\n",
      "223 1977-07-01    unemp     6.900  0.479803\n",
      "488 1999-07-01     infl     3.350  2.076974\n",
      "164 1972-07-01     infl     3.810  0.121510\n"
     ]
    }
   ],
   "source": [
    "data_pivot = long_data.pivot(index=\"date\", \n",
    "                             columns=\"item\", \n",
    "                             values=\"value\")\n",
    "\n",
    "print(\"Pivoted long format Data:\\n\", data_pivot.head(),\"\\n\", sep='')\n",
    "\n",
    "# Adding new value column\n",
    "long_data[\"value2\"] = np.random.standard_normal(len(long_data))\n",
    "print(\"Long Data with new column:\\n\",long_data.sample(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted long format Data:\n",
      "           value                    value2                    \n",
      "item        infl   realgdp unemp      infl   realgdp     unemp\n",
      "date                                                          \n",
      "1959-01-01  0.00  2710.349   5.8  1.109704  0.478075  0.778557\n",
      "1959-04-01  2.34  2778.801   5.1  1.902302 -0.332077  0.835549\n",
      "1959-07-01  2.74  2775.488   5.3  1.053750  1.354385 -0.812201\n",
      "1959-10-01  0.27  2785.204   5.6  0.520720 -1.477654 -2.297180\n",
      "1960-01-01  2.31  2847.699   5.2 -0.483893  0.509806 -1.351570\n",
      "\n",
      "\n",
      "Showing only value2:\n",
      "item            infl   realgdp     unemp\n",
      "date                                    \n",
      "1959-01-01  1.109704  0.478075  0.778557\n",
      "1959-04-01  1.902302 -0.332077  0.835549\n",
      "1959-07-01  1.053750  1.354385 -0.812201\n",
      "1959-10-01  0.520720 -1.477654 -2.297180\n",
      "1960-01-01 -0.483893  0.509806 -1.351570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pivoting long data without passing values, this generate hierarchical columns\n",
    "data_pivot = long_data.pivot(index=\"date\", \n",
    "                             columns=\"item\")\n",
    "\n",
    "print(\"Pivoted long format Data:\\n\", data_pivot.head(),\"\\n\", sep='')\n",
    "print(\"\\nShowing only value2:\\n\", data_pivot[\"value2\"].head(),\"\\n\", sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same result of 'pivot()' but using 'unstack()' and 'set_index()'\n",
      "           value                    value2                    \n",
      "item        infl   realgdp unemp      infl   realgdp     unemp\n",
      "date                                                          \n",
      "1959-01-01  0.00  2710.349   5.8  1.109704  0.478075  0.778557\n",
      "1959-04-01  2.34  2778.801   5.1  1.902302 -0.332077  0.835549\n",
      "1959-07-01  2.74  2775.488   5.3  1.053750  1.354385 -0.812201\n",
      "1959-10-01  0.27  2785.204   5.6  0.520720 -1.477654 -2.297180\n",
      "1960-01-01  2.31  2847.699   5.2 -0.483893  0.509806 -1.351570\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    'pivot' method is equivalent to creating a hierarchical index \n",
    "    using 'set_index' folowed by a call to unstack\n",
    "\"\"\"\n",
    "\n",
    "data_unstack = long_data.set_index([\"date\", \"item\"]).unstack(level=\"item\")\n",
    "\n",
    "print(\"Same result of 'pivot()' but using 'unstack()' and 'set_index()'\\n\",\n",
    "      data_unstack.head(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting \"Wide\" to \"Long\" Format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
