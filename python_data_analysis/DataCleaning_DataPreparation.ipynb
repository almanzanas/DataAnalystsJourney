{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "Data Preparation tasks such as loading, cleaning, trasforming and rearranging are ofen reported to take up 80% or more of an analyst's time. Pandas and other python features provide flexible and fast set of tools for manipulate data into the right form.\n",
    "\n",
    "## Index\n",
    "\n",
    "* [Handling Missing Data](#handling-missing-data)\n",
    "    * [Filtering Out Missing Data](#filtering-out-missing-data)\n",
    "    * [Filling In Missing Data](#filling-in-missing-data)\n",
    "* [Data Transformation](#data-transformation)\n",
    "    * [Removing Duplicates](#removing-duplicates)\n",
    "    * [Trasforming Data Using a Function or Mapping](#trasforming-data-using-a-function-or-mapping)\n",
    "    * [Replacing Values](#replacing-values)\n",
    "    * [Renaming Axis Indexes](#renaming-axis-indexes)\n",
    "    * [Discretization and Binning](#discretization-and-binning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "*NA handling object methods*\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|dropna |Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate.|\n",
    "|fillna |Fill in missing data with some value or using an interpolation method such as \"ffill\" or \"bfill\".|\n",
    "|isna |Return Boolean values indicating which values are missing/NA.|\n",
    "|notna |Negation of isna, returns True for non-NA values and False for NA values|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series \n",
      "0    1.2\n",
      "1   -3.5\n",
      "2    NaN\n",
      "3    0.0\n",
      "dtype: float64\n",
      "\n",
      "Missing data: \n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "Series \n",
      "0    1.2\n",
      "1   -3.5\n",
      "2    NaN\n",
      "3    0.0\n",
      "4    NaN\n",
      "dtype: float64\n",
      "\n",
      "Missing data: \n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "flo_data = pd.Series([1.2, -3.5, np.nan, 0])\n",
    "\n",
    "print(f\"Series \\n{flo_data}\")\n",
    "print(f\"\\nMissing data: \\n{flo_data.isna()}\")\n",
    "\n",
    "# python 'None', is also treated as NA\n",
    "flo_data = pd.Series([1.2, -3.5, np.nan, 0, None])\n",
    "\n",
    "print(f\"\\nSeries \\n{flo_data}\")\n",
    "print(f\"\\nMissing data: \\n{flo_data.isna()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Out Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series wthout NA values: \n",
      "0    1.2\n",
      "1   -3.5\n",
      "3    0.0\n",
      "dtype: float64\n",
      "\n",
      "Using filter flo_data[flo_data.notna()]: \n",
      "0    1.2\n",
      "1   -3.5\n",
      "3    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "flo_data = pd.Series([1.2, -3.5, np.nan, 0, None])\n",
    "\n",
    "print(f\"Series wthout NA values: \\n{flo_data.dropna()}\")\n",
    "# Same result with filter\n",
    "print(f\"\\nUsing filter flo_data[flo_data.notna()]: \\n{flo_data[flo_data.notna()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFrame: \n",
      "     0    1    2\n",
      "0  2.0  5.5  3.0\n",
      "1  2.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  5.5  3.0\n",
      "\n",
      "DFrame without rows containing NA values: \n",
      "     0    1    2\n",
      "0  2.0  5.5  3.0\n",
      "\n",
      "DFrame dropping full NA rows: \n",
      "     0    1    2\n",
      "0  2.0  5.5  3.0\n",
      "1  2.0  NaN  NaN\n",
      "3  NaN  5.5  3.0\n",
      "DFrame with new column 4 with NA values: \n",
      "     0    1    2   4\n",
      "0  2.0  5.5  3.0 NaN\n",
      "1  2.0  NaN  NaN NaN\n",
      "2  NaN  NaN  NaN NaN\n",
      "3  NaN  5.5  3.0 NaN\n",
      "\n",
      "Dropping full NA columns specifying axis:\n",
      "     0    1    2\n",
      "0  2.0  5.5  3.0\n",
      "1  2.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  5.5  3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame([[2., 5.5, 3.], \n",
    "                      [2., np.nan, np.nan], \n",
    "                      [np.nan, np.nan, np.nan], \n",
    "                      [np.nan, 5.5, 3.]])\n",
    "\n",
    "print(f\"DFrame: \\n{frame}\")\n",
    "\n",
    "print(f\"\\nDFrame without rows containing NA values: \\n{frame.dropna()}\")\n",
    "print(f\"\\nDFrame dropping full NA rows: \\n{frame.dropna(how='all')}\")\n",
    "\n",
    "frame[4] = np.nan \n",
    "print(f\"DFrame with new column 4 with NA values: \\n{frame}\")\n",
    "print(f\"\\nDropping full NA columns specifying axis:\"\n",
    "      f\"\\n{frame.dropna(axis='columns', how='all')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "          0         1         2\n",
      "0 -0.424858       NaN       NaN\n",
      "1 -0.156521       NaN       NaN\n",
      "2 -0.475313       NaN  0.014500\n",
      "3 -0.299724       NaN -0.754694\n",
      "4 -0.068748 -0.675605  0.069436\n",
      "5 -0.223925 -0.006411  2.636000\n",
      "6 -1.614529  1.470182 -1.130516\n",
      "\n",
      "Dropping rows with NA values: \n",
      "          0         1         2\n",
      "4 -0.068748 -0.675605  0.069436\n",
      "5 -0.223925 -0.006411  2.636000\n",
      "6 -1.614529  1.470182 -1.130516\n",
      "\n",
      "Dropping rows with at least 2 NA values: \n",
      "          0         1         2\n",
      "2 -0.475313       NaN  0.014500\n",
      "3 -0.299724       NaN -0.754694\n",
      "4 -0.068748 -0.675605  0.069436\n",
      "5 -0.223925 -0.006411  2.636000\n",
      "6 -1.614529  1.470182 -1.130516\n"
     ]
    }
   ],
   "source": [
    "## Keep rows with at most a certain number of missing observations\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df = pd.DataFrame(np.random.standard_normal((7,3)))\n",
    "df.iloc[:4, 1] = np.nan \n",
    "df.iloc[:2, 2] = np.nan \n",
    "\n",
    "print(f\"DataFrame: \\n{df}\")\n",
    "\n",
    "print(f\"\\nDropping rows with NA values: \\n{df.dropna()}\")\n",
    "\n",
    "print(f\"\\nDropping rows with at least 2 NA values: \\n{df.dropna(thresh=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling In Missing Data\n",
    "\n",
    "Filling misssing data prevent us of discard some data with it. The `fillna()` method will help in this task. Otherwise, we can use *method='ffill'* argument with or without *limit* to fill NA values with values of the other cells in the same column. Now, argument *method='ffill'* is deprecated, instead we can use `ffill()` method or `bfill()` method.\n",
    "\n",
    "*fillna Function arguments*\n",
    "|Argument|Description|\n",
    "|---|---|\n",
    "|value |Scalar value or dictionary-like object to use to fill missing values|\n",
    "|method |Interpolation method: one of \"bfill\" (backward fill) or \"ffill\" (forward fill); default is None|\n",
    "|axis |Axis to fill on (\"index\" or \"columns\"); default is axis=\"index\"|\n",
    "|limit |For forward and backward filling, maximum number of consecutive periods to fill|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "          0         1         2\n",
      "0 -0.260455       NaN       NaN\n",
      "1 -1.361895       NaN       NaN\n",
      "2  0.485779       NaN -0.932451\n",
      "3 -0.977748       NaN  0.855924\n",
      "4  0.173131  1.399493  0.354406\n",
      "5  0.039476 -0.582290 -1.913124\n",
      "6 -0.291814  0.146749 -0.044685\n",
      "\n",
      "DataFrame filling NA with '0': \n",
      "          0         1         2\n",
      "0 -0.260455  0.000000  0.000000\n",
      "1 -1.361895  0.000000  0.000000\n",
      "2  0.485779  0.000000 -0.932451\n",
      "3 -0.977748  0.000000  0.855924\n",
      "4  0.173131  1.399493  0.354406\n",
      "5  0.039476 -0.582290 -1.913124\n",
      "6 -0.291814  0.146749 -0.044685\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df = pd.DataFrame(np.random.standard_normal((7,3)))\n",
    "df.iloc[:4, 1] = np.nan \n",
    "df.iloc[:2, 2] = np.nan \n",
    "\n",
    "print(f\"DataFrame: \\n{df}\")\n",
    "\n",
    "print(f\"\\nDataFrame filling NA with '0': \\n{df.fillna(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "          0         1         2\n",
      "0  0.925019  0.332396  1.077413\n",
      "1  0.360310  0.789294  0.749743\n",
      "2  0.606949       NaN -0.234555\n",
      "3 -0.404238       NaN  1.091170\n",
      "4 -2.075037       NaN       NaN\n",
      "5 -0.521436       NaN       NaN\n",
      "6 -0.551778       NaN       NaN\n",
      "\n",
      "DataFrame filling NA with values in the same column:\n",
      "          0         1         2\n",
      "0  0.925019  0.332396  1.077413\n",
      "1  0.360310  0.789294  0.749743\n",
      "2  0.606949  0.789294 -0.234555\n",
      "3 -0.404238  0.789294  1.091170\n",
      "4 -2.075037       NaN  1.091170\n",
      "5 -0.521436       NaN  1.091170\n",
      "6 -0.551778       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df = pd.DataFrame(np.random.standard_normal((7,3)))\n",
    "df.iloc[2:, 1] = np.nan \n",
    "df.iloc[4:, 2] = np.nan \n",
    "\n",
    "print(f\"DataFrame: \\n{df}\")\n",
    "\n",
    "#print(f\"\\nDataFrame filling NA with values in the same column:\"\n",
    "#      f\"\\n{df.fillna(method='ffill', limit=2)}\")\n",
    "\n",
    "print(f\"\\nDataFrame filling NA with values in the same column:\"\n",
    "      f\"\\n{df.ffill(limit=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Series: \n",
      "0    1.0\n",
      "1    NaN\n",
      "2    3.5\n",
      "3    NaN\n",
      "4    7.0\n",
      "dtype: float64\n",
      "\n",
      "Fillin NA with 'mean': \n",
      "0    1.000000\n",
      "1    3.833333\n",
      "2    3.500000\n",
      "3    3.833333\n",
      "4    7.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Filling data in a Series with the mean of the series\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "data = pd.Series([1., np.nan, 3.5, np.nan, 7])\n",
    "\n",
    "print(f\"\\nOriginal Series: \\n{data}\")\n",
    "\n",
    "print(f\"\\nFillin NA with 'mean': \\n{data.fillna(data.mean())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "\n",
    "### Removing Duplicates\n",
    "\n",
    "The DataFrame method `duplicated` returns a True or False whether or not the row is a duplicate (its column values are exactly eual to those in an earlier row). `drop_duplicated()` discards duplicated rows. By default `duplicated()` and `drop_duplicated()` keep the first observed value, we can change this behavior passing the argument `keep=\"last\"`, this will keep the last observerd rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "    k1  k2\n",
      "0  one   1\n",
      "1  two   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "4  one   3\n",
      "5  two   4\n",
      "6  two   4\n",
      "\n",
      "Duplicated rows: \n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "\n",
      "Dropping Duplicates: \n",
      "    k1  k2\n",
      "0  one   1\n",
      "1  two   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "4  one   3\n",
      "5  two   4\n",
      "\n",
      "Non-duplicated values based on 'K1' column:\n",
      "    k1  k2  v1\n",
      "0  one   1   0\n",
      "1  two   1   1\n",
      "\n",
      "Drop duplicates keeping last rows:\n",
      "    k1  k2  v1\n",
      "0  one   1   0\n",
      "1  two   1   1\n",
      "2  one   2   2\n",
      "3  two   3   3\n",
      "4  one   3   4\n",
      "6  two   4   6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame({\n",
    "    \"k1\": [\"one\", \"two\"] * 3 + [\"two\"],\n",
    "    \"k2\": [1, 1, 2, 3, 3, 4, 4]\n",
    "})\n",
    "\n",
    "print(f\"DataFrame: \\n{frame}\")\n",
    "\n",
    "print(f\"\\nDuplicated rows: \\n{frame.duplicated()}\")\n",
    "\n",
    "# Returning DataFrame without duplicated rows \n",
    "print(f\"\\nDropping Duplicates: \\n{frame.drop_duplicates()}\")\n",
    "\n",
    "# Add column 'v1' with range(7)\n",
    "frame[\"v1\"] = range(7)\n",
    "\n",
    "# Duplicated values based only on \"k1\" column\n",
    "print(f\"\\nNon-duplicated values based on 'K1' column:\"\n",
    "      f\"\\n{frame.drop_duplicates(subset=['k1'])}\")\n",
    "\n",
    "# Keeping last observed values\n",
    "print(f\"\\nDrop duplicates keeping last rows:\"\n",
    "      f\"\\n{frame.drop_duplicates(['k1', 'k2'], keep='last')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trasforming Data Using a Function or Mapping\n",
    "\n",
    "Next, we are going to add a column based on other dictionary. We'll use `map()` method which accepts a function or dictionary-like object containing a mapping to do the transformation of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "          food  ounces\n",
      "0        bacon     4.0\n",
      "1  pulled pork     3.0\n",
      "2        bacon    12.0\n",
      "3     pastrami     6.0\n",
      "4  corned beef     7.5\n",
      "5        bacon     8.0\n",
      "6     pastrami     3.0\n",
      "7    honey ham     5.0\n",
      "8     nova lox     6.0\n",
      "\n",
      "Dictionary, meat that corresponds to which animal:\n",
      "{'bacon': 'pig', 'pulled pork': 'pig', 'pastrami': 'cow', 'corned beef': 'cow', 'honey ham': 'pig', 'nova lox': 'salmon'}\n",
      "\n",
      "Updated DataFrame: \n",
      "          food  ounces  animal\n",
      "0        bacon     4.0     pig\n",
      "1  pulled pork     3.0     pig\n",
      "2        bacon    12.0     pig\n",
      "3     pastrami     6.0     cow\n",
      "4  corned beef     7.5     cow\n",
      "5        bacon     8.0     pig\n",
      "6     pastrami     3.0     cow\n",
      "7    honey ham     5.0     pig\n",
      "8     nova lox     6.0  salmon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "frame = pd.DataFrame({\n",
    "    \"food\": [\"bacon\", \"pulled pork\", \"bacon\",\n",
    "             \"pastrami\", \"corned beef\", \"bacon\",\n",
    "             \"pastrami\", \"honey ham\", \"nova lox\"],\n",
    "             \"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]\n",
    "})\n",
    "\n",
    "meat_to_animal = {\n",
    "    \"bacon\": \"pig\",\n",
    "    \"pulled pork\": \"pig\",\n",
    "    \"pastrami\": \"cow\",\n",
    "    \"corned beef\": \"cow\",\n",
    "    \"honey ham\": \"pig\",\n",
    "    \"nova lox\": \"salmon\"\n",
    "}\n",
    "\n",
    "print(f\"DataFrame: \\n{frame}\")\n",
    "print(f\"\\nDictionary, meat that corresponds to which animal:\"\n",
    "      f\"\\n{meat_to_animal}\")\n",
    "\n",
    "# Creating \"animal\" column in 'frame'\n",
    "# Then, considering 'food' column we map() the 'meat_to_animal' dictionary \n",
    "frame[\"animal\"] = frame[\"food\"].map(meat_to_animal)\n",
    "\n",
    "\"\"\"\n",
    "Alternative using a function:\n",
    "def get_animal(x):\n",
    "    return meat_to_animal[x]\n",
    "\n",
    "frame[\"animal\"] = frame[\"food\"].map(get_animal)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nUpdated DataFrame: \\n{frame}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values\n",
    "\n",
    "Sometimes, extreme values like -999 represents missing data. `replace()` can provides a simpler and more flexible way to modidy values than `map()`. The `data.replace()` method is distinct from `data.str.replace()` which performs element-wise string substitution.\n",
    "```python\n",
    "# Replace one value:\n",
    "data.replace(-999, np.nan)\n",
    "# Replace a list of values:\n",
    "data.replace([-999, -1000], np.nan)\n",
    "# Replace with diferent values:\n",
    "data.replace([-999, -1000], [np.nan, 0])\n",
    "# Replace with a dictionary:\n",
    "data.replace({-999: np.nan, -1000: 0})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Axis Indexes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before changes: \n",
      "          one  two  three  four\n",
      "Ohio        0    1      2     3\n",
      "Colorado    4    5      6     7\n",
      "New York    8    9     10    11\n",
      "\n",
      "DataFrame after changes: \n",
      "      ONE  TWO  THREE  FOUR\n",
      "Ohio    0    1      2     3\n",
      "Colo    4    5      6     7\n",
      "New     8    9     10    11\n",
      "\n",
      "DataFrame after renaming: \n",
      "         one  two  peekaboo  four\n",
      "INDIANA    0    1         2     3\n",
      "COLO       4    5         6     7\n",
      "NEW        8    9        10    11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "\n",
    "# Function returning first 4 letters in uppercase \n",
    "def transform(x):\n",
    "    return x[:4].upper()\n",
    "\n",
    "print(f\"DataFrame before changes: \\n{data}\")\n",
    "# Modifying the DataFrame index directly\n",
    "data.index = data.index.map(transform)\n",
    "\n",
    "# And renaming as title case, no uppercase\n",
    "data2 = data.rename(index=str.title, columns=str.upper)\n",
    "\n",
    "print(f\"\\nDataFrame after changes: \\n{data2}\")\n",
    "\n",
    "# Renaming with dictionary\n",
    "data3 = data.rename(index={\"OHIO\": \"INDIANA\"},\n",
    "                    columns={\"three\": \"peekaboo\"})\n",
    "\n",
    "print(f\"\\nDataFrame after renaming: \\n{data3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning\n",
    "\n",
    "Continuous data is often discretized or otherwise separated into 'bins' for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
