df.higher.samp <- df.higher.w %>%
rep_sample_n( size = 1000, reps = 200, replace = TRUE ) %>%
summarize( mu_Median = mean(Median),
mu_Low_wage = mean(Low_wage_jobs) )
df.lower.samp <- df.lower.w %>%
rep_sample_n( size = 1000, reps = 200, replace = TRUE ) %>%
summarize( mu_Median = mean(Median),
mu_Low_wage = mean(Low_wage_jobs) )
shapiro.test(df.lower.samp$mu_Median)
shapiro.test(df.higher.samp$mu_Median)
shapiro.test(df.lower.samp$mu_Low_wage)
shapiro.test(df.higher.samp$mu_Low_wage)
t.test(df.higher.samp$mu_Median, df.lower.samp$mu_Median)
t.test(df.higher.samp$mu_Low_wage, df.lower.samp$mu_Low_wage)
df.salary.w <- df.clean %>%
group_by(ShareWomen_cat) %>%
summarize(Salary_mean = mean(Median) )
ggplot( data = df.clean ) +
geom_boxplot( aes( x = ShareWomen_cat, y = Median),
fill = "lightblue", color = "darkblue" ) +
labs( title = "Average Salary When
ShareWomen is lower/higher than 50%",
subtitle = "The average salary for majors with more women enrolled \n
is lower than the majors with less women, reinforcing the perception \n
that women are getting lower salaries.",
x = "50% Share of Women",
y = "Mean Salary" ) +
geom_text( data = df.salary.w, aes( x = ShareWomen_cat,
y = Salary_mean,
label = round(Salary_mean)),
size = 2.2, vjust = 1, color = "black" ) +
theme(plot.subtitle = element_text( color = "darkgray", size = 9 ) )
library(tidyverse)
library(datasets)
library(patchwork)
data("mtcars")
ggplot(mtcars) +
geom_histogram(
mapping = aes( x = mpg ),
bins = 20,
color = "lightblue",
fill = "darkblue",
alpha = 0.6
) +
ggtitle( "Whistogram of Miles per Gallon" )
ggplot( data = mtcars ) +
geom_boxplot( aes( y = mpg ), fill = "lightblue", color = "darkblue" ) +
ggtitle( "Boxplot of miles per gallon")
ggplot( mtcars ) +
geom_boxplot( aes( x = factor(am),
y = mpg ), fill = "lightblue" ) +
labs( x = "Transmission",
title = "Comparison betweeen automatic and manual transmission on MPG",
subtitle = "The median of manual cars (1) is higher" )
ggplot( data = mtcars ) +
geom_point( aes( x = wt, y = mpg ),
color = "darkblue",
size = 4,
shape = 15, # squares
alpha = 0.7 ) +
labs ( x = "Weight of the cars",
y = "Milles per Gallon",
title = "How the weight affects MPG in cars?",
subtitle = "As the weight increases, the car will maje less MPG")
ggplot( mtcars ) +
geom_bar( aes( x = factor(am),
fill = factor(am) ) ) +
# Fill in 'aes' using the same factor means color per category
labs( x = "Automatic(0) | Manual(1)" ) +
ggtitle( "Count of observations by transmission type" )
ggplot( mtcars ) +
geom_bar( aes( x = factor(am),
y = mpg,
fill = factor(am) ),
stat = "summary", fun = "mean" ) # To use the mean on 'y' axis
ggplot( mtcars ) +
stat_summary( aes( x = factor(am),
y = mpg,
fill = factor(am) ),
fun = "mean",
geom = "bar" )
# Alternative to the previous graphic
ggplot( mtcars ) +
geom_col( aes( x = factor(am),
y = mpg,
fill = factor(am) ) ) +
labs( x = "Automatic(0) | Manual(1)" )
ggplot( mtcars ) +
geom_bar( aes( x = factor(cyl), fill = factor(vs) ),
position = "stack" )
ggplot( mtcars ) +
geom_bar( aes( x = factor(cyl), fill = factor(vs) ),
position = "dodge" )
ggplot( mtcars ) +
geom_bar( aes( x = factor(cyl), fill = factor(vs) ),
position = "fill" )
df.line <- data.frame(
month = seq(1, 12, 1),
sales = rlnorm(12),
sales2 = rgamma(12, 1)
)
df.line[1:5,]
ggplot( df.line ) +
geom_line( aes( x = month,
y = sales,
group = 1),
linewidth = 1,
color = "darkblue" ) +
ggtitle( "Car sales throughout the months")
ggplot( df.line ) +
geom_line( aes( x = month,
y = sales,
group = 1,
color = "Sales year 1"), # the label for this line
linewidth = 1,
linetype = 2) +
geom_line( aes( x = month,
y = sales2,
group = 1,
color = "Sales year 2"),
linewidth = 1,
linetype = 1) +
ggtitle( "Car sales throughout the monts" ) +
labs( subtitle = "Two year comparison",
color = "Sales Year") # The title for the legend
ggplot( mtcars ) +
geom_point( aes( x = hp,
y = mpg,
color = factor(vs) ) ) +
geom_smooth( aes( x = hp,
y = mpg ),
method = 'loess' )
ggplot( mtcars, aes( x = hp, y = mpg ) ) +
geom_point( aes( color = factor(vs) ) ) +
geom_smooth( method = 'loess' )
ggplot( mtcars, aes( x = hp, y = mpg ) ) +
geom_point( aes( color = factor(vs) ) ) +
geom_smooth( method = 'loess' ) +
theme_bw()
ggplot( mtcars, aes( x = hp, y = mpg ) ) +
geom_point( aes( color = factor(vs) ) ) +
geom_smooth( method = 'loess' ) +
theme_minimal()
ggplot( mtcars, aes( x = hp, y = mpg ) ) +
geom_point( aes( color = factor(vs) ) ) +
geom_smooth( method = 'loess' ) +
theme_linedraw()
library(tidyverse)
library(lubridate)
library(datasets)
library(patchwork)
library(plotly)
data("diamonds")
df.diam <- diamonds
ggplot( df.diam ) +
geom_point( aes( x = carat, y = price,
color = factor(cut), alpha = 0.5) )
ggplot( df.diam ) +
geom_point( aes( x = carat, y = price,
color = factor(cut),
alpha = 0.5 ) ) +
facet_grid(rows = vars(cut) ) +
theme( legend.position = "none" )
ggplot( df.diam ) +
geom_point( aes( x = carat, y = price,
color = cut, alpha = 0.6 ) ) +
facet_grid( rows = vars(cut), cols = vars(clarity) ) +
theme_minimal() +
theme( legend.position = "none")
g <- ggplot( df.diam ) +
geom_point( aes( x = carat, y = price,
color = factor(cut),
alpha = 0.5 ) ) +
facet_grid(rows = vars(cut) ) +
theme_minimal() +
theme( legend.position = "none" )
g + facet_wrap( vars(cut) )
# Load the map
us <- map_data("state")
# Load the dataset:
url <- "https://raw.githubusercontent.com/PacktPublishing/Data-Wrangling-with-R/main/Part3/Chapter11/USA_states.csv"
states <- read_csv(url)
remove(url)
# 'state' column to lowercase
states <- states %>% mutate( state = str_to_lower(state) )
# Map locations
us_map <- ggplot( states ) +
geom_map( aes( longitude, latitude,
map_id = state),
map = us, color = "black", fill = "azure" ) +
xlim(-130, -60) +
ylim(20,55) +
theme_void()
us_map +
geom_point( aes( x = longitude,
y = latitude,
size = GDP,
fill = GDP),
shape = 24 )
df.time <- data.frame(
date = seq(ymd('2022-01-01'), ymd('2022-06-30'), by = 'days'),
measure = as.integer(runif(181, min = 600, max = 1000) +
sort( rexp( 181, 0.001 ) ) )
)
head(df.time)
basic.plot <- ggplot( df.time ) +
geom_line( aes( x = date, y = measure ), size = 0.8 ) +
theme_minimal()
basic.plot
basic.plot +
scale_x_date(date_breaks = "4 weeks", date_labels = "%W %y")
basic.plot +
scale_x_date(date_breaks = "1 weeks", date_labels = "%d %m",
limit=as.Date( c("2022-05-01", "2022-06-01") ) )
# Surface 3D plot
surface <- matrix( as.integer( sort( abs( runif(160, 90, 180) ) ) ),
nrow = 80, ncol = 20 )
plot_ly(z = ~ surface) %>% add_surface()
# 2D and 3D comparison
var1 = rnorm(20, mean = 25, sd = 5 )
var2 = var1 + rgamma(20,1)
df.2d3d <- data.frame( var1 = var1,
var2 = var2,
var3 = 1:20,
var4 = rep( c("A", "B"), each = 10) )
## plot 2d
ggplot(df.2d3d) +
geom_point( aes( x = var1, y = var2, color = var4 ) )
# Plot 3d
plot_ly( df.2d3d, x = ~var1, y = ~var2, z = ~var3,
color = ~var4, colors = c("turquoise", "coral") ) %>%
add_markers()   # To add the points
ggplotly(
ggplot( df.diam ) +
geom_point( aes( x = carat, y = price,
color = factor(cut), alpha = 0.5) )
)
library(tidyverse)
library(wordcloud2)
library(officer)
library(tidytext)
var1 = rnorm(200, mean = 25, sd = 5)
var2 = var1 + rnorm(200, mean = 25, sd = 15)
df.pwbi <- data.frame( var1 = var1,
var2 = var2,
var3 = 1:200,
var4 = rep( c("A", "B", "C", "D"), each = 50) )
write_csv(df.pwbi, "../data/r2pwrbi.csv")
#dataset <- df.pwbi
library(ggplot2)
ggplot(dataset) +
geom_histogram( aes(var1), bins = 10,
color = "azure", fill = "darkblue") +
labs( title = "Histogram of Variable 1",
subtitle = "Random variable visualization on Power BI") +
theme_minimal()
data(dataset)
dataset <- df.pwbi
library(ggplot2)
ggplot(dataset) +
geom_histogram( aes(var1), bins = 10,
color = "azure", fill = "darkblue") +
labs( title = "Histogram of Variable 1",
subtitle = "Random variable visualization on Power BI") +
theme_minimal()
library(tidyverse)
library(wordcloud2)
library(officer)
library(tidytext)
doc.text <- read_docx("../data/Chapter10_for_wordcloud.docx")
content <- docx_summary(doc.text)
head(content)
text <- content %>%
select(text)
text <- na_if(text[["text"]], "")
text <- tibble(text)
text <- text %>% drop_na()
text.tokens <- text %>%
unnest_tokens( output = word, input = text )
text.tokens %>% head()
text.tk.clean <- text.tokens %>%
filter( str_detect(word, "\\D") )
text.tk.clean <- text.tk.clean %>%
filter( !str_detect(word, "[:punct:]"))
data(stop_words)
text.tk.clean <- text.tk.clean %>%
anti_join(stop_words)
word.freq <- text.tk.clean %>%
count(word, sort = TRUE)
head(word.freq, 10)
wordcloud2(data = word.freq, color = "random-dark", size = 1)
library(tidyverse)
library(patchwork)
library(skimr)
library(randomForest)
library(caret)
library(ROCR)
url.data <- "https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data"
url.names <- "https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names"
names <- read_table(url.names, col_names = FALSE) %>% suppressWarnings()
names <- names %>% filter(X2 == "continuous.") %>% select(X1)
names <- names %>% mutate(X1 = gsub(pattern = "\\:", replacement = "", x = X1) )
df <- read_csv(url.data,
col_names = c(names[["X1"]], "spam_cat"),
trim_ws = TRUE) %>% suppressWarnings()
glimpse(df)
dim(df)
dim(df)   # Dataset previously loaded
glimpse(df)
vars.int <- c("capital_run_length_average",
"capital_run_length_longest",
"capital_run_length_total")
df <- df %>%
mutate_at("spam_cat", as.factor) %>%
mutate_at(vars.int, as.integer)
anyNA(df)
# Disable scientific notion
options( scipen = 999, digits = 4 )
skim(df)
for (var in colnames(select_if(df[,1:47], is.numeric) ) ) {
hist( unlist( df[,var]), col = "blue",
main = paste("Histogram of", var),
xlab = var)
}
df.long <- df %>%
pivot_longer( cols = 1:57, names_to = "words", values_to = "pct")
head(df.long, 9)
df.long %>%
filter( str_detect(words, "word_") & spam_cat == 1) %>%
ggplot() +
geom_boxplot( aes( y = reorder(words, pct), x = pct, fill = spam_cat ) ) +
labs( title = "Percentages of words and their association with spam emails",
subtitle = "The frequency of appearance of some words in emails is more associated with spam",
x = "Percentage",
y = "Word" ) +
theme_classic() +
theme( plot.subtitle = element_text( color = "darkgray", size = 10 ),
legend.position = "none")
temp <- df.long %>%
filter( str_detect(words, "word_") & spam_cat == 1) %>%
group_by(words) %>%
summarise( pct_sum = sum(pct) ) %>%
arrange( desc(pct_sum) )
top.words <- c(temp$words[1:23], "spam_cat")
remove(temp)
df.top <- df %>%
select( all_of(top.words) ) %>%
mutate( top_words_pct = rowSums( across( where(is.numeric) ) ) )
g1 <- ggplot(df.top) +
geom_boxplot( aes( y = factor(spam_cat), x = top_words_pct),
fill = c("turquoise", "coral") ) +
labs( title = "How the presence of words associated with spam emails
impacts the classification (TOP23)",
subtitle = "The spam emails(1) have a ghigher percentage of those words.") +
theme_classic()
df.2 <- df %>%
mutate(word_pct = rowSums( across( where(is.numeric) ) ) )
g2 <- ggplot(df.2) +
geom_boxplot( aes( y = factor(spam_cat), x = word_pct ),
fill = c("turquoise", "coral") ) +
labs( title = "How spam associated words impacts the classification",
subtitle = "The spam emails(1) have a ghigher percentage of those words.") +
theme_classic()
# Patchwork library, putting the objects into a parenthesis with a pipe
(g1 | g2)
pos.spam <- df.top[df.top["spam_cat"] == 1,][["top_words_pct"]]
neg.spam <- df.top[df.top["spam_cat"] == 0,][["top_words_pct"]]
ks.test(pos.spam, neg.spam)
wilx <- wilcox.test(pos.spam, neg.spam)
wilx
# Size effect formula by Wendt
rbis <- sum(-1, (2 * wilx$statistic) / (length(pos.spam) * length(neg.spam)) )
cat("U Mann Whitney effect size r = ", rbis)
df.long %>%
filter( str_detect(words, "char_") & spam_cat == 1) %>%
ggplot() +
geom_boxplot( aes( y = reorder(words, pct), x = pct, fill = spam_cat ) ) +
labs( title = "Percentages of special characters and their association with spam emails",
subtitle = "The frequency of appearance of some characters in emails is more associated with spam",
x = "Percentage",
y = "Character" ) +
theme_classic() +
theme( plot.subtitle = element_text( color = "darkgray", size = 10 ),
legend.position = "none")
df.char <- df %>%
select_if(str_detect(colnames(df), pattern = "char_|^spam_cat")) %>%
mutate( char_pct = rowSums( across( where(is.numeric) ) ) )
g3 <- ggplot(df.char) +
geom_boxplot( aes( y = factor(spam_cat), x = char_pct),
fill = c("turquoise", "coral") ) +
labs( title = "How the presence of characters associated with spam emails
impacts the classification",
subtitle = "The spam emails(1) have a ghigher percentage of those characters.") +
theme_classic()
g3
df.char.zero <- df.char %>% filter(spam_cat == 0)
df.char.one <- df.char %>% filter(spam_cat == 1)
for (var in colnames(df.char.zero[,1:6])) {
wilx <- wilcox.test(df.char.zero[[var]], df.char.one[[var]])
rbis <- abs(sum(-1, (2 * wilx$statistic) / (length(pos.spam) * length(neg.spam)) ))
cat("\nMann-Whitney U between spam and not spam on:", var,
"\np-value:", sprintf("%6.4f", wilx$p.value),
"\nr:", rbis)
}
g4 <- df.char.zero %>%
pivot_longer(cols = 1:6, names_to = "chars", values_to = "pct") %>%
ggplot() +
geom_boxplot( aes( y = chars, x = pct) ) +
labs( y = "Characters in not spam emails",
x = "") +
theme_classic()
g5 <- df.char.one %>%
pivot_longer(cols = 1:6, names_to = "chars", values_to = "pct") %>%
ggplot() +
geom_boxplot( aes( y = chars, x = pct) ) +
labs( x = "Frequencies",
y = "Characters in spam emails") +
theme_classic()
(g4 / g5)
df.model <- df %>%
bind_cols( top_words_pct = df.top$top_words_pct ) %>%
select( spam_cat, top_words_pct,
`char_freq_!`, `char_freq_(`, `char_freq_$`,
capital_run_length_total, capital_run_length_longest ) %>%
mutate(spam_cat = ifelse(spam_cat == 1, "is_spam", "no_spam")) %>%
mutate_at(vars(spam_cat), as.factor)
colnames(df.model)[3:5] <- c("char_freq_exclam", "char_freq_paren", "char_freq_dollar")
slice_sample(df.model, n = 9)
n.rows <- nrow(df.model)
idx <- sample(1:n.rows, size = 0.8 * n.rows)
train.80 <- df.model[idx,]
test.20 <- df.model[-idx,]
writeLines("Original set:")
prop.table( table(df$spam_cat) )
writeLines("==================")
writeLines("Train set:")
prop.table( table(train.80$spam_cat) )
writeLines("==================")
writeLines("Test set:")
prop.table( table(test.20$spam_cat) )
model.rf <- randomForest( spam_cat ~ ., data = train.80,
importance = TRUE,
ntree = 250)
plot(model.rf)
varImpPlot(model.rf)
# Prediction:
model.preds <- predict(model.rf, test.20)
confusionMatrix(model.preds, test.20$spam_cat, positive = "no_spam")
model.df.preds <- data.frame( predict(model.rf, test.20, type='prob') )
model.roc <- prediction(model.df.preds$no_spam, test.20$spam_cat)
roc <- performance(model.roc, 'tpr', 'fpr')
auc <- performance(model.roc, "auc")
plot(roc, colorize = T, lwd = 2,
main = "ROC curve. 'no_spam' as positive class.",
sub = paste( "AUC =", auc@y.values[[1]]) )
abline(0.0, 1.0)
# Creating a function to prepare any text for input in the model
prepare_input <- function (text, spam_words){
"This function takes a string text as input, counts the quantities of !, $, (), uppercase letters, longest sequence of uppercase, words in the spam list.
* Input: string
* Returns: data frame for input in the RF model"
# Counts of the punctuation
exclamation <- str_count(text, pattern="[!]")
parenthesis <-  str_count(text, pattern="[()]")
dollar_sign <-  str_count(text, pattern="[$]")
# Counts of UPPERCASE
total_uppercase <- str_count(text, "[A-Z]")
# Remove punctuation for total words count
text_no_puncuation <- str_remove_all(text, pattern="[:punct:]|[$]*")
#longest_uppercase
all_words <- str_split(text_no_puncuation, " ")
all_words <- all_words[[1]]
# Create a vector with all the uppercase counts
char_counts <- c()
for (word in all_words) {
if (word == toupper(word)) {
char_counts <- c(char_counts, nchar(word))
} #enf if
}#end for
# Get only the longest uppercase word size
if (max(char_counts) < 0) {
longest_upper <- 0} else {longest_upper <- max(char_counts)}
# Count how many spam words are in the text
# Create a counter of spam words
top_w <- 0
# For each word
for (word in all_words) {
# if word is in the spam list, count +1
if (tolower(word) %in% spam_words) {
top_w <- top_w + 1
} #enf if
}#end for
# Determine length of the text
text_length <- length(all_words)
# Create a data frame with all counts in percentages (divided by the text length)
input <- data.frame(top_words_pct= 100*top_w / text_length,
char_freq_exclam= 100*exclamation / text_length,
char_freq_paren= 100*parenthesis / text_length,
char_freq_dollar= 100*dollar_sign / text_length,
capital_run_length_total= total_uppercase,
capital_run_length_longest= longest_upper )
return(input)
} #end function
text1 <- 'SALE!! SALE!! SALE!! SUPER SALEEEE!! This is one of the best sales of the year! More than #3000# products with discounts up to $500 off!! Visit our page and Save $$$ now! Order your product NOW (here) and get one for free !'
text2 <- 'DEAR MR. JOHN, You will find enclosed the file we talked about during your meeting earlier today. The attachment received here is also available in our web site at this address: www.DUMMYSITE.com. Sale.'
spam.words <- c('you', 'your', 'will', 'free', 'our', 'all', 'mail', 'email', 'business', 'remove', '000', 'font', 'money', 'internet', 'credit', 'over', 'order', '3d', 'address', 'make', 'people', 're', 'receive', 'sale')
input <- prepare_input(text1, spam.words)
data.frame( predict(model.rf, input, type = "prob") )
input <- prepare_input(text2, spam.words)
data.frame( predict(model.rf, input, type = "prob") )
saveRDS(model.rf, "../scripts/model_rf_spam.rds")
gc()
